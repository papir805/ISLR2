{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa3ed09-da5c-4459-af7e-64c300ace29c",
   "metadata": {},
   "source": [
    "# 5.3 Lab: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971b8db2-93b9-48d1-b7a1-532cd9eb8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de60a8c-442a-4cf8-a098-1f4d43548616",
   "metadata": {},
   "source": [
    "## 5.3.1 The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac918b6-fbd5-4a7c-b431-e68012c64811",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ISLR2)\n",
    "set.seed(1)\n",
    "train <- sort(sample(392, 196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c183fb-bef6-4854-9edc-d36330912731",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robjects.r(\"\"\"\n",
    "library(ISLR2)\n",
    "set.seed(1)\n",
    "train <- sample(392, 196)\n",
    "\"\"\")\n",
    "\n",
    "train_idx = np.array(data)\n",
    "train_idx = np.sort(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07abd7e2-9aad-4bf2-9ba0-ca96be169846",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = pd.read_csv(\"../../../datasets/Auto.csv\", na_values='?')\n",
    "\n",
    "# Reset index labels to start at 1 to match R's behavior\n",
    "auto_df = auto_df.set_index(keys=np.arange(1, len(auto_df) + 1))\n",
    "\n",
    "# Drow rows that contain '?' values that represent na values\n",
    "auto_df = auto_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c508f122-4b71-4852-b238-6a1e08a0e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since boolean masks work using integer labels for indexing, this mimics the behavior in R nicely.  It also makes it easyto get the testing indices by negating the training indices.\n",
    "\n",
    "auto_df_no_gaps = auto_df.copy(deep=True)\n",
    "\n",
    "auto_df_no_gaps= auto_df_no_gaps.set_index(np.arange(1, auto_df_no_gaps.shape[0] + 1))\n",
    "\n",
    "auto_train_mask_no_gaps = auto_df_no_gaps.index.isin(train_idx)\n",
    "\n",
    "auto_test_mask_no_gaps = ~auto_train_mask_no_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84c8c11-7ec3-425d-8ca0-cd64735a382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107da2c7-6d3b-4466-bf18-b5020565c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = mpg ~ horsepower, data = Auto, subset = train)\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median      3Q     Max \n",
      "-9.3177 -3.5428 -0.5591  2.3910 14.6836 \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept) 41.283548   1.044352   39.53   <2e-16 ***\n",
      "horsepower  -0.169659   0.009556  -17.75   <2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Residual standard error: 5.032 on 194 degrees of freedom\n",
      "Multiple R-squared:  0.619,\tAdjusted R-squared:  0.6171 \n",
      "F-statistic: 315.2 on 1 and 194 DF,  p-value: < 2.2e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary(lm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "123e0bce-e2e7-449c-aa35-81f333e93c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   315.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>1.61e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:21:05</td>     <th>  Log-Likelihood:    </th> <td> -593.80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1192.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   194</td>      <th>  BIC:               </th> <td>   1198.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   41.2835</td> <td>    1.044</td> <td>   39.530</td> <td> 0.000</td> <td>   39.224</td> <td>   43.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   -0.1697</td> <td>    0.010</td> <td>  -17.754</td> <td> 0.000</td> <td>   -0.189</td> <td>   -0.151</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.451</td> <th>  Durbin-Watson:     </th> <td>   1.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  14.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.662</td> <th>  Prob(JB):          </th> <td>0.000714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.149</td> <th>  Cond. No.          </th> <td>    318.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.619\n",
       "Model:                            OLS   Adj. R-squared:                  0.617\n",
       "Method:                 Least Squares   F-statistic:                     315.2\n",
       "Date:                Mon, 23 Jan 2023   Prob (F-statistic):           1.61e-42\n",
       "Time:                        23:21:05   Log-Likelihood:                -593.80\n",
       "No. Observations:                 196   AIC:                             1192.\n",
       "Df Residuals:                     194   BIC:                             1198.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     41.2835      1.044     39.530      0.000      39.224      43.343\n",
       "horsepower    -0.1697      0.010    -17.754      0.000      -0.189      -0.151\n",
       "==============================================================================\n",
       "Omnibus:                       13.451   Durbin-Watson:                   1.171\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.488\n",
       "Skew:                           0.662   Prob(JB):                     0.000714\n",
       "Kurtosis:                       3.149   Cond. No.                         318.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_model = smf.ols(formula = 'mpg ~ horsepower', data = auto_df_no_gaps, subset=train_idx)\n",
    "lm_fit = lm_model.fit()\n",
    "\n",
    "lm_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e58fa4-7cb4-4f9c-a231-6c3e086c89db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 23.26601\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "attach(Auto)\n",
    "mean((mpg - predict(lm.fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3862df21-81cb-4f36-ae60-d55e6989ac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.2660086465003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lm_fit.predict(auto_df_no_gaps[auto_test_mask_no_gaps]['horsepower'])\n",
    "((auto_df_no_gaps[auto_test_mask_no_gaps]['mpg'] - pred)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b62bd-7c93-4a9e-9523-bb4a3d1246a5",
   "metadata": {},
   "source": [
    "### Polynomial Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ed33e-c6f7-4ab8-bcfb-c16a0feffa3e",
   "metadata": {},
   "source": [
    "#### 2nd Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "257de8b6-31c7-4b92-8b1c-8466e92a55ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
      "\n",
      "Residuals:\n",
      "     Min       1Q   Median       3Q      Max \n",
      "-12.8711  -2.6655  -0.0096   2.0806  16.1063 \n",
      "\n",
      "Coefficients:\n",
      "                      Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)            23.5496     0.3175  74.182  < 2e-16 ***\n",
      "poly(horsepower, 2)1 -123.5881     6.4587 -19.135  < 2e-16 ***\n",
      "poly(horsepower, 2)2   47.7189     6.3613   7.501 2.25e-12 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Residual standard error: 4.439 on 193 degrees of freedom\n",
      "Multiple R-squared:  0.705,\tAdjusted R-squared:  0.702 \n",
      "F-statistic: 230.6 on 2 and 193 DF,  p-value: < 2.2e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
    "summary(lm.fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c388c5b4-55c1-4bcb-abe9-9040876598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(2, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b415b9e3-d423-44ee-9ec4-029c63009772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   230.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>6.83e-52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:21:05</td>     <th>  Log-Likelihood:    </th> <td> -568.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1143.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   193</td>      <th>  BIC:               </th> <td>   1153.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                      <td></td>                                         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                                 <td>   58.8738</td> <td>    2.519</td> <td>   23.368</td> <td> 0.000</td> <td>   53.905</td> <td>   63.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[0]</th> <td>   -0.4961</td> <td>    0.044</td> <td>  -11.192</td> <td> 0.000</td> <td>   -0.584</td> <td>   -0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[1]</th> <td>    0.0013</td> <td>    0.000</td> <td>    7.501</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.485</td> <th>  Durbin-Watson:     </th> <td>   1.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  16.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.354</td> <th>  Prob(JB):          </th> <td>0.000204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.257</td> <th>  Cond. No.          </th> <td>1.21e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.21e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.705\n",
       "Model:                            OLS   Adj. R-squared:                  0.702\n",
       "Method:                 Least Squares   F-statistic:                     230.6\n",
       "Date:                Mon, 23 Jan 2023   Prob (F-statistic):           6.83e-52\n",
       "Time:                        23:21:05   Log-Likelihood:                -568.72\n",
       "No. Observations:                 196   AIC:                             1143.\n",
       "Df Residuals:                     193   BIC:                             1153.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================================================================\n",
       "                                                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                    58.8738      2.519     23.368      0.000      53.905      63.843\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[0]    -0.4961      0.044    -11.192      0.000      -0.584      -0.409\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[1]     0.0013      0.000      7.501      0.000       0.001       0.002\n",
       "==============================================================================\n",
       "Omnibus:                       11.485   Durbin-Watson:                   1.232\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               16.996\n",
       "Skew:                           0.354   Prob(JB):                     0.000204\n",
       "Kurtosis:                       4.257   Cond. No.                     1.21e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.21e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(2, include_bias=False)\n",
    "\n",
    "lm_model2_poly_feats  = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(horsepower).reshape(-1,1))', data = auto_df_no_gaps, subset=train_idx)\n",
    "lm_fit2_poly_feats = lm_model2_poly_feats.fit()\n",
    "\n",
    "lm_fit2_poly_feats.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b2f20-7d01-4c43-a103-3750f1aa17fe",
   "metadata": {},
   "source": [
    "**Using PolynomialFeatures with smf.ols doesn't produce the same model as poly and lm in R.  Although the models look different, that's because PolynomialFeatures returns an array where the vectors aren't orthogonalized, whereas poly in R does.  When the array isn't orthogonalized, the inputs are much larger and affect the coefficients for the model, hence the difference.**\n",
    "\n",
    "**If I generate the model in R using poly(horsepower, 2, raw=TRUE), then poly doesn't return an orthogonalized array and the coefficients of the model in R and Python match.  If I was able to orthogonalize the array from PolynomialFeatures in Python, then I think the models would generate the same coefficients.  I may look into this later, but it's a little unncessary and plan to proceed ahead for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c359913-1f22-441e-a8b6-40d143a55d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 18.71646\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "mean((mpg - predict(lm.fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9b0a90-6858-44b5-9ecc-25e71716da6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.716459493382548"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2_poly_feats = lm_fit2_poly_feats.predict(auto_df_no_gaps[auto_test_mask_no_gaps]['horsepower'])\n",
    "\n",
    "((pred2_poly_feats - auto_df_no_gaps[auto_test_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d3f4a-36a0-4d1b-aa9f-bce3d04d4744",
   "metadata": {},
   "source": [
    "**The MSE from using PolynomialFeatures with smf.ols matches in Python and R, despite the models between Python and R not entirely matching.  This is due to the difference in inputs where poly returns orthogonalized vectors while PolynomialFeatures doesn't.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261f570-e274-4127-9a22-4e645e31068a",
   "metadata": {},
   "source": [
    "#### 3rd Degree Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877ffad-b4bc-4add-8dcd-2eb940cb9d58",
   "metadata": {},
   "source": [
    "##### Checking that ortho_poly_fit and smf.ols produce same model as poly and lm in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89b0d568-f81a-4aa3-9ae0-58b531f5a33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = mpg ~ poly(horsepower, 3), data = Auto, subset = train)\n",
      "\n",
      "Residuals:\n",
      "     Min       1Q   Median       3Q      Max \n",
      "-12.6625  -2.7108   0.0805   2.0724  16.1378 \n",
      "\n",
      "Coefficients:\n",
      "                      Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)            23.5527     0.3185  73.946  < 2e-16 ***\n",
      "poly(horsepower, 3)1 -123.6143     6.4755 -19.089  < 2e-16 ***\n",
      "poly(horsepower, 3)2   47.8284     6.3935   7.481 2.58e-12 ***\n",
      "poly(horsepower, 3)3    1.3825     5.8107   0.238    0.812    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Residual standard error: 4.45 on 192 degrees of freedom\n",
      "Multiple R-squared:  0.7051,\tAdjusted R-squared:  0.7005 \n",
      "F-statistic:   153 on 3 and 192 DF,  p-value: < 2.2e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)\n",
    "summary(lm.fit3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "159eaa7d-ddf0-451f-b937-8ede7748e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   153.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>1.14e-50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:21:05</td>     <th>  Log-Likelihood:    </th> <td> -568.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1145.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   192</td>      <th>  BIC:               </th> <td>   1158.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                      <td></td>                                         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                                 <td>   57.5977</td> <td>    5.928</td> <td>    9.715</td> <td> 0.000</td> <td>   45.904</td> <td>   69.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[0]</th> <td>   -0.4610</td> <td>    0.154</td> <td>   -2.989</td> <td> 0.003</td> <td>   -0.765</td> <td>   -0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[1]</th> <td>    0.0010</td> <td>    0.001</td> <td>    0.831</td> <td> 0.407</td> <td>   -0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[2]</th> <td> 7.515e-07</td> <td> 3.16e-06</td> <td>    0.238</td> <td> 0.812</td> <td>-5.48e-06</td> <td> 6.98e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.392</td> <th>  Durbin-Watson:     </th> <td>   1.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  16.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.365</td> <th>  Prob(JB):          </th> <td>0.000287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.211</td> <th>  Cond. No.          </th> <td>4.71e+07</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.71e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.705\n",
       "Model:                            OLS   Adj. R-squared:                  0.701\n",
       "Method:                 Least Squares   F-statistic:                     153.0\n",
       "Date:                Mon, 23 Jan 2023   Prob (F-statistic):           1.14e-50\n",
       "Time:                        23:21:05   Log-Likelihood:                -568.69\n",
       "No. Observations:                 196   AIC:                             1145.\n",
       "Df Residuals:                     192   BIC:                             1158.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================================================================\n",
       "                                                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                    57.5977      5.928      9.715      0.000      45.904      69.291\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[0]    -0.4610      0.154     -2.989      0.003      -0.765      -0.157\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[1]     0.0010      0.001      0.831      0.407      -0.001       0.004\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[2]  7.515e-07   3.16e-06      0.238      0.812   -5.48e-06    6.98e-06\n",
       "==============================================================================\n",
       "Omnibus:                       11.392   Durbin-Watson:                   1.228\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               16.312\n",
       "Skew:                           0.365   Prob(JB):                     0.000287\n",
       "Kurtosis:                       4.211   Cond. No.                     4.71e+07\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.71e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(3, include_bias=False)\n",
    "\n",
    "lm_model3_poly_feats  = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(horsepower).reshape(-1,1))', data = auto_df_no_gaps, subset=train_idx)\n",
    "lm_fit3_poly_feats = lm_model3_poly_feats.fit(method='qr')\n",
    "\n",
    "lm_fit3_poly_feats.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3753207-5874-4fcd-ae08-74936b2d971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 18.79401\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "mean((mpg - predict(lm.fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b71aaca-849c-47b3-89d7-00cb8d578a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.794006797394548"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3_poly_feats = lm_fit3_poly_feats.predict(auto_df_no_gaps[~auto_train_mask_no_gaps])\n",
    "\n",
    "((pred3_poly_feats - auto_df_no_gaps[~auto_train_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f8be7-884c-4e94-b71f-1d9bdd24bae8",
   "metadata": {},
   "source": [
    "**The MSE from using PolynomialFeatures with smf.ols matches in Python and R, despite the models between Python and R not entirely matching.  This is due to the difference in inputs where poly returns orthogonalized vectors while PolynomialFeatures doesn't.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd992fe1-476b-4d2a-84f4-390138048a1c",
   "metadata": {},
   "source": [
    "### Generating new training indices and reealuting MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a021dfd-4251-4541-865d-5af6acf5ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 25.72651\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(2)\n",
    "train <- sample(392, 196)\n",
    "lm.fit <- lm(mpg ~ horsepower, subset = train)\n",
    "mean((mpg - predict(lm.fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d1fb51-a6ab-4b74-b3e2-7cf1930f817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robjects.r(\"\"\"\n",
    "library(ISLR2)\n",
    "set.seed(2)\n",
    "train <- sample(392, 196)\n",
    "\"\"\")\n",
    "\n",
    "new_train_idx = np.array(data)\n",
    "new_train_idx = np.sort(new_train_idx)\n",
    "\n",
    "new_auto_train_mask_no_gaps = auto_df_no_gaps.index.isin(new_train_idx)\n",
    "new_auto_test_mask_no_gaps = ~new_auto_train_mask_no_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb54b82c-c2a0-4ed4-89d9-1105a584aa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.726510644813906"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_model = smf.ols(formula='mpg ~ horsepower', data = auto_df_no_gaps, subset = new_train_idx)\n",
    "\n",
    "lm_fit = lm_model.fit()\n",
    "\n",
    "pred = lm_fit.predict(auto_df_no_gaps[~new_auto_train_mask_no_gaps]['horsepower'])\n",
    "\n",
    "((pred - auto_df_no_gaps[~new_auto_train_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e699d4-a196-4a0a-b2b5-c67623b265a3",
   "metadata": {},
   "source": [
    "#### Polynomial Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff19e6b-77c8-4d2e-a7f4-23f3e9da5ba5",
   "metadata": {},
   "source": [
    "##### 2nd Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e547520b-00d3-4f39-a3c0-1e6e178bc55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 20.43036\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
    "mean((mpg - predict(lm.fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8071ee1f-4a51-4017-979f-506ba9f144f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.430364274145607"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(2, include_bias=False)\n",
    "\n",
    "new_lm_model2_poly_feats  = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(horsepower).reshape(-1,1))', data = auto_df_no_gaps, subset=new_train_idx)\n",
    "new_lm_fit2_poly_feats = new_lm_model2_poly_feats.fit()\n",
    "\n",
    "new_pred2_poly_feats = new_lm_fit2_poly_feats.predict(auto_df_no_gaps[new_auto_test_mask_no_gaps]['horsepower'])\n",
    "\n",
    "((new_pred2_poly_feats - auto_df_no_gaps[new_auto_test_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9605f01-5eab-4ab0-a5a5-c5129a6f3e96",
   "metadata": {},
   "source": [
    "**Same MSE in R and Python despite models being slightly different due to input vectors not being orthogonalized in Python.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd825d5-e6da-44d2-b6fe-6acc49e86852",
   "metadata": {},
   "source": [
    "##### 3rd Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2361356c-7c76-4faa-9c49-12c2efc560e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 20.38533\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)\n",
    "mean((mpg - predict(lm.fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94a6d5a0-4da8-4999-b591-60aa2e90b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.385326863877566"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(3, include_bias=False)\n",
    "\n",
    "new_lm_model3_poly_feats  = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(horsepower).reshape(-1,1))', data = auto_df_no_gaps, subset=new_train_idx)\n",
    "new_lm_fit3_poly_feats = new_lm_model3_poly_feats.fit(method='qr')\n",
    "\n",
    "new_pred3_poly_feats = new_lm_fit3_poly_feats.predict(auto_df_no_gaps[new_auto_test_mask_no_gaps]['horsepower'])\n",
    "\n",
    "((new_pred3_poly_feats - auto_df_no_gaps[new_auto_test_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68079c29-7ca9-45ad-92d1-9491e388603f",
   "metadata": {},
   "source": [
    "**Same MSE in R and Python despite models being slightly different due to input vectors not being orthogonalized in Pytho.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d8280-82bf-42e4-8f22-759c818387b9",
   "metadata": {},
   "source": [
    "## 5.3.2 Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6433786-21b8-4a7f-bbdc-c316fad34835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 39.9358610  -0.1578447 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "glm.fit <- glm(mpg ~ horsepower, data = Auto)\n",
    "coef(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c59d2c81-8019-4a72-a237-9ad6ef074e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_model = smf.glm(formula='mpg ~ horsepower', data=auto_df_no_gaps)\n",
    "glm_fit = glm_model.fit()\n",
    "glm_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63621bdb-fb64-402e-a65e-aa491b66bfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 39.9358610  -0.1578447 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit <- lm(mpg ~ horsepower, data = Auto)\n",
    "coef(lm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bf22026-6c88-4d2f-b34b-04a390c2d150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_model = smf.ols(formula = 'mpg ~ horsepower', data=auto_df_no_gaps)\n",
    "lm_fit = lm_model.fit()\n",
    "lm_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01f576fa-f9d7-45e9-94ec-ab9d24c98813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 24.23151 24.23114\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(boot)\n",
    "glm.fit <- glm(mpg ~ horsepower, data = Auto)\n",
    "cv.err <- cv.glm(Auto, glm.fit)\n",
    "cv.err$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d5f15d5-ae38-4772-826b-86308b47d28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929226"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = auto_df_no_gaps['horsepower'].values.reshape(-1,1)\n",
    "y = auto_df_no_gaps['mpg'].values.reshape(-1,1)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "skl_lm_model = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "scores = cross_val_score(skl_lm_model, X, y, cv = loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "np.mean(np.abs(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69002c6-8735-43cb-95e2-a10379b450ca",
   "metadata": {},
   "source": [
    "### Polynomial Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60101c94-1d28-403f-8548-9a95295bf16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 24.23151 19.24821 19.33498 19.42443 19.03321 18.97864 18.83305 18.96115\n",
      " [9] 19.06863 19.49093\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "cv.error <- rep(0, 10)\n",
    "for (i in 1:10) {\n",
    "    glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "    cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]\n",
    "}\n",
    "cv.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5eb1f17-cc96-4ed2-b829-1ce16de04fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.231513517929226,\n",
       " 19.24821312448967,\n",
       " 19.33498406402931,\n",
       " 19.42443031024277,\n",
       " 19.03321248615882,\n",
       " 18.97863406819667,\n",
       " 19.129480449254846,\n",
       " 19.224150660848743,\n",
       " 19.133322843461364,\n",
       " 18.93976572079586]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    polynomial_features = sklearn.preprocessing.PolynomialFeatures(i, include_bias=False)\n",
    "\n",
    "    scores = cross_val_score(skl_lm_model, polynomial_features.fit_transform(X), y, cv = loo, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    mean_score = np.mean(np.abs(scores))\n",
    "    \n",
    "    cv_error.append(mean_score)\n",
    "    \n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496c4eb-9f2e-44bf-a7e9-13c9ae941fe4",
   "metadata": {},
   "source": [
    "**The MSEs match closely in Python and R.  All but the last 4 entries match exactly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f426b-17f0-494e-8578-5a8265b30d8a",
   "metadata": {},
   "source": [
    "## 5.3.3 k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "462759e9-4db6-443e-80cf-507dd0968aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666\n",
      " [9] 18.87013 20.95520\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(17)\n",
    "cv.error.10 <- rep(0, 10)\n",
    "for (i in 1:10) {\n",
    "    glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "    cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]\n",
    "}\n",
    "cv.error.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19219a18-a8a5-409c-96ec-98f7d06827c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27.439933652339874,\n",
       " 21.235840055802225,\n",
       " 21.33660618322788,\n",
       " 21.35388698195473,\n",
       " 20.905641650770082,\n",
       " 20.779180086179668,\n",
       " 20.990939391569672,\n",
       " 21.077615424551695,\n",
       " 21.036905853431772,\n",
       " 20.977623972381583]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error_10 = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    polynomial_features = sklearn.preprocessing.PolynomialFeatures(i, include_bias=False)\n",
    "\n",
    "    scores = cross_val_score(skl_lm_model, polynomial_features.fit_transform(X), y, cv = 10, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    mean_score = np.mean(np.abs(scores))\n",
    "    \n",
    "    cv_error_10.append(mean_score)\n",
    "    \n",
    "cv_error_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059d0e1-c6d0-40fe-b965-518dc90669af",
   "metadata": {},
   "source": [
    "**Because the folds are randomly generated, the folds generated from cv.glm in R are likely to be different than the folds generates from cross_val_score in Python and we shouldn't expect the bootstrap MSEs to match, but we'd expect them to be similar.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483edd91-662b-43d0-a5c7-b45cc2b7ddd1",
   "metadata": {},
   "source": [
    "## 5.3.4 The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6048885-19be-4e43-9d55-126ebf58e1a9",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Statistic of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "498f4fff-d285-487c-8e8e-761ae6e33547",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "alpha.fn <- function(data, index) {\n",
    "    X <- data$X[index]\n",
    "    Y <- data$Y[index]\n",
    "    (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e819ff38-856a-4c79-8e3b-580db7e65920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.5758321\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "alpha.fn(Portfolio, 1:100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb230e72-101a-4606-8c8f-630f58f5473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfolio_df = pd.read_csv(\"../../../datasets/Portfolio.csv\")\n",
    "pfolio_df = pfolio_df.set_index(np.arange(1, pfolio_df.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18e249ca-2a09-4664-93e8-01874e3afb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_fn(data, index):\n",
    "    X = data.loc[index]['X']\n",
    "    Y = data.loc[index]['Y']\n",
    "    var_x = np.var(X, ddof=1)\n",
    "    var_y = np.var(Y, ddof=1)\n",
    "    cov_x_y = np.cov(X, Y, ddof=1)[0][1]\n",
    "    \n",
    "    return (var_y - cov_x_y) / (var_x + var_y - 2 * cov_x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adbe2647-b26f-414e-8ae5-47f2c1030611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758320745928298"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_fn(pfolio_df, np.arange(1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bebb3c0b-be93-418c-b4b4-1095b44ffedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.5385326\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(7)\n",
    "alpha.fn(Portfolio, sample(100, 100, replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e24bd8f-f495-4201-9664-7a94f10e910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robjects.r(\"\"\"\n",
    "set.seed(7)\n",
    "train <- sample(100, 100, replace=T)\n",
    "\"\"\")\n",
    "\n",
    "bstrap_idx = np.array(data)\n",
    "bstrap_idx = np.sort(bstrap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7753848-79c3-4579-ba09-dccb79be8438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385325919467925"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_fn(pfolio_df, bstrap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c62bb2d-3e5f-44c3-aac8-606ce540a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
      "\n",
      "\n",
      "Call:\n",
      "boot(data = Portfolio, statistic = alpha.fn, R = 1000)\n",
      "\n",
      "\n",
      "Bootstrap Statistics :\n",
      "     original       bias    std. error\n",
      "t1* 0.5758321 0.0007959475  0.08969074\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot(Portfolio, alpha.fn, R = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "263a1707-bc5f-41bc-8345-b65fba303bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Alpha: 0.5758320745928298\n",
      "Alpha Bias: 0.0018467314323676876\n",
      "Alpha Std: 0.09286469104959781\n"
     ]
    }
   ],
   "source": [
    "## Note: the boot package from R automatically creates bootstrap samples of length n, where n = the number of observations in the dataset you pass to boot.  In order to mimic that behavior in Python, we need np.random.choice to choose n numbers to ensure the bootstrap sample has the same number of observations as in the dataset.\n",
    "\n",
    "alphas = []\n",
    "n = pfolio_df.shape[0]\n",
    "\n",
    "for _ in range(1000):\n",
    "    idx = np.random.choice(np.arange(1, n+1), n)\n",
    "    alpha = alpha_fn(pfolio_df, idx)\n",
    "    alphas.append(alpha)\n",
    "    \n",
    "original_alpha = alpha_fn(pfolio_df, np.arange(1, n+1))\n",
    "alpha_bstrap_mean = np.mean(alphas)\n",
    "alpha_bstrap_std = np.std(alphas, ddof=1) ## When calculating the std dev, np.std divides by N-ddof.  To find the sample std dev, we set ddof=1\n",
    "\n",
    "## Bias = bootstrap realization of the statistic - the original statistic from the original data\n",
    "alpha_bias = alpha_bstrap_mean - original_alpha\n",
    "\n",
    "print(f'Original Alpha: {original_alpha}')\n",
    "print(f'Alpha Bias: {alpha_bias}')\n",
    "print(f'Alpha Std: {alpha_bstrap_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cb5cd-7edb-4ed9-89f3-a176fdc94efb",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1be0656c-b54f-42ba-932c-8441a8afc74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 39.9358610  -0.1578447 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot.fn <- function(data, index)\n",
    "    coef(lm(mpg ~ horsepower, data = data, subset = index))\n",
    "boot.fn(Auto, 1:392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e658f53-75f8-490e-bebf-3bbde0567c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_fn(data, index):\n",
    "    model = smf.glm(formula = 'mpg ~ horsepower', data = data, subset = index)\n",
    "    fit = model.fit()\n",
    "    coefficients = fit.params\n",
    "    \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9e43d20-510a-46f5-9d2c-d80bea79259d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_fn(auto_df_no_gaps, np.arange(1, 393))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "921c4cec-f786-47b3-add4-76a2b7caec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 40.3404517  -0.1634868 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(1)\n",
    "boot.fn(Auto, sample(392, 392, replace = T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ffbbb87-ae69-415c-a942-a0dd7660bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robjects.r(\"\"\"\n",
    "set.seed(1)\n",
    "samp <- sample(392, 392, replace=T)\n",
    "\"\"\")\n",
    "\n",
    "bstrap_idx = np.array(data)\n",
    "bstrap_idx = np.sort(bstrap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "783cf2dd-31b1-409e-8c90-e754635bc3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     40.340452\n",
       "horsepower    -0.163487\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_fn(auto_df_no_gaps, bstrap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fb99a65-4c45-4849-8869-4947bfc805e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 40.1186906  -0.1577063 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot.fn(Auto, sample(392, 392, replace = T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c220c1d-c1a1-4997-811d-bfb48ee16607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     40.227766\n",
       "horsepower    -0.162126\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(np.arange(1,393), 392)\n",
    "boot_fn(auto_df_no_gaps, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad73adb9-829a-421c-82c7-7d7a4f71e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
      "\n",
      "\n",
      "Call:\n",
      "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
      "\n",
      "\n",
      "Bootstrap Statistics :\n",
      "      original        bias    std. error\n",
      "t1* 39.9358610  0.0544513229 0.841289790\n",
      "t2* -0.1578447 -0.0006170901 0.007343073\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c920b000-9519-45e6-a0d3-75c547d49ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Intercept: 39.93586102117048\n",
      "Bstrap Intercept Bias: -0.00867467112543352\n",
      "Bstrap Intercept Std: 0.892766093263005\n",
      "\n",
      "Original Slope: -0.15784473335365357\n",
      "Bstrap Slope Bias: 8.926628730326902e-05\n",
      "Bstrap Slope Std: 0.00762841271663687\n"
     ]
    }
   ],
   "source": [
    "intercepts = []\n",
    "slopes = []\n",
    "\n",
    "n = auto_df_no_gaps.shape[0]\n",
    "\n",
    "for _ in range(1000):\n",
    "    idx = np.random.choice(np.arange(1, n+1), n)\n",
    "    param = boot_fn(auto_df_no_gaps, idx)\n",
    "    intercept = param[0]\n",
    "    slope = param[1]\n",
    "    intercepts.append(intercept)\n",
    "    slopes.append(slope)\n",
    "\n",
    "original_intercept = boot_fn(auto_df_no_gaps, np.arange(1, 393))[0]\n",
    "original_slope = boot_fn(auto_df_no_gaps, np.arange(1, 393))[1]\n",
    "intercept_bstrap_mean = np.mean(intercepts)\n",
    "intercept_bstrap_std = np.std(intercepts, ddof=1) ## When calculating the std dev, np.std divides by N-ddof.  To find the sample std dev, we set ddof=1\n",
    "slope_bstrap_mean = np.mean(slopes)\n",
    "slope_bstrap_std = np.std(slopes, ddof=1)\n",
    "\n",
    "## Bias = bootstrap realization of the statistic - the original statistic from the original data\n",
    "## bias for intercepts\n",
    "intercept_bias = intercept_bstrap_mean - original_intercept\n",
    "\n",
    "## bias for slopes\n",
    "slope_bias = slope_bstrap_mean - original_slope\n",
    "\n",
    "print(f'Original Intercept: {original_intercept}')\n",
    "print(f'Bstrap Intercept Bias: {intercept_bias}')\n",
    "print(f'Bstrap Intercept Std: {intercept_bstrap_std}')\n",
    "print()\n",
    "print(f'Original Slope: {original_slope}')\n",
    "print(f'Bstrap Slope Bias: {slope_bias}')\n",
    "print(f'Bstrap Slope Std: {slope_bstrap_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57299887-57d8-496a-9544-8e543f979b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Estimate  Std. Error   t value      Pr(>|t|)\n",
      "(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\n",
      "horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary(lm(mpg ~ horsepower, data = Auto))$coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8027c3c-4560-44b9-b4ba-28c86eb12b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>39.9359</td>\n",
       "      <td>0.717</td>\n",
       "      <td>55.660</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.1578</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-24.489</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coef  std err       t  P>|t|\n",
       "Intercept   39.9359    0.717  55.660    0.0\n",
       "horsepower  -0.1578    0.006 -24.489    0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://stackoverflow.com/questions/51734180/converting-statsmodels-summary-object-to-pandas-dataframe\n",
    "\n",
    "results = smf.ols(formula = 'mpg ~ horsepower', data = auto_df_no_gaps).fit().summary().tables[1]\n",
    "\n",
    "results_as_html = results.as_html()\n",
    "results_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "results_df[['coef', 'std err', 't', 'P>|t|']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16bdc454-405e-42ac-a9c6-1e0d6f89d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
      "\n",
      "\n",
      "Call:\n",
      "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
      "\n",
      "\n",
      "Bootstrap Statistics :\n",
      "        original        bias     std. error\n",
      "t1* 56.900099702  3.511640e-02 2.0300222526\n",
      "t2* -0.466189630 -7.080834e-04 0.0324241984\n",
      "t3*  0.001230536  2.840324e-06 0.0001172164\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot.fn <- function(data, index)\n",
    "    coef(\n",
    "      lm(mpg ~ horsepower + I(horsepower^2),\n",
    "        data = data, subset = index)\n",
    "    )\n",
    "\n",
    "set.seed(1)\n",
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06ec9a20-07c7-4555-8ca7-7e31483f7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What does I() do in the formula: https://stackoverflow.com/questions/24192428/what-does-the-capital-letter-i-in-r-linear-regression-formula-mean\n",
    "\n",
    "def boot_fn(data, index):\n",
    "    model = smf.ols(formula='mpg ~ horsepower + I(horsepower**2)', \n",
    "                    data=data, \n",
    "                    subset=index)\n",
    "    fit = model.fit()\n",
    "    params = fit.params\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecc3eca3-2299-462f-b21b-3dcba0b2eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = []\n",
    "hp_1s = []\n",
    "hp_2s = []\n",
    "\n",
    "n = auto_df_no_gaps.shape[0]\n",
    "\n",
    "for _ in range(1000):\n",
    "    idx = np.random.choice(np.arange(1, n+1), n)\n",
    "    param = boot_fn(auto_df_no_gaps, idx)\n",
    "    intercept = param[0]\n",
    "    hp_1 = param[1]\n",
    "    hp_2 = param[2]\n",
    "    intercepts.append(intercept)\n",
    "    hp_1s.append(hp_1)\n",
    "    hp_2s.append(hp_2)\n",
    "\n",
    "original_intercept = boot_fn(auto_df_no_gaps, np.arange(1, 393))[0]\n",
    "original_hp_1 = boot_fn(auto_df_no_gaps, np.arange(1, 393))[1]\n",
    "original_hp_2 = boot_fn(auto_df_no_gaps, np.arange(1, 393))[2]\n",
    "\n",
    "intercept_bstrap_mean = np.mean(intercepts)\n",
    "intercept_bstrap_std = np.std(intercepts, ddof=1) ## When calculating the std dev, np.std divides by N-ddof.  To find the sample std dev, we set ddof=1\n",
    "\n",
    "hp_1_bstrap_mean = np.mean(hp_1s)\n",
    "hp_1_bstrap_std = np.std(hp_1s, ddof=1)\n",
    "\n",
    "hp_2_bstrap_mean = np.mean(hp_2s)\n",
    "hp_2_bstrap_std = np.std(hp_2s, ddof=1)\n",
    "\n",
    "## Bias = bootstrap realization of the statistic - the original statistic from the original data\n",
    "## bias for intercepts\n",
    "intercept_bias = intercept_bstrap_mean - original_intercept\n",
    "\n",
    "## bias for horsepower\n",
    "hp_1_bias = hp_1_bstrap_mean - original_hp_1\n",
    "\n",
    "## bias for horsepower**2\n",
    "hp_2_bias = hp_2_bstrap_mean - original_hp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c3d9770-8fc5-443e-803a-7265c31dcac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Intercept: 56.90009970211517\n",
      "Bstrap Intercept Bias: 0.021694888257798084\n",
      "Bstrap Intercept Std: 2.1200659809299682\n",
      "\n",
      "Original Slope: -0.46618962994736257\n",
      "Bstrap horsepower Bias: -0.000384803575593784\n",
      "Bstrap horsepower Std: 0.03388658575935158\n",
      "\n",
      "Original Slope: 0.0012305361007737656\n",
      "Bstrap horsepower**2 Bias: 1.2778057296998057e-06\n",
      "Bstrap horsepower**2 Std: 0.00012272733089463907\n"
     ]
    }
   ],
   "source": [
    "print(f'Original Intercept: {original_intercept}')\n",
    "print(f'Bstrap Intercept Bias: {intercept_bias}')\n",
    "print(f'Bstrap Intercept Std: {intercept_bstrap_std}')\n",
    "print()\n",
    "print(f'Original Slope: {original_hp_1}')\n",
    "print(f'Bstrap horsepower Bias: {hp_1_bias}')\n",
    "print(f'Bstrap horsepower Std: {hp_1_bstrap_std}')\n",
    "print()\n",
    "print(f'Original Slope: {original_hp_2}')\n",
    "print(f'Bstrap horsepower**2 Bias: {hp_2_bias}')\n",
    "print(f'Bstrap horsepower**2 Std: {hp_2_bstrap_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "028fbcc0-346a-4e79-863f-3928410c49bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Estimate   Std. Error   t value      Pr(>|t|)\n",
      "(Intercept)     56.900099702 1.8004268063  31.60367 1.740911e-109\n",
      "horsepower      -0.466189630 0.0311246171 -14.97816  2.289429e-40\n",
      "I(horsepower^2)  0.001230536 0.0001220759  10.08009  2.196340e-21\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary(\n",
    "    lm(mpg ~ horsepower + I(horsepower^2), data = Auto)\n",
    ")$coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0c20474-381c-451e-b372-0de82fb82a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>56.9001</td>\n",
       "      <td>1.800</td>\n",
       "      <td>31.604</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.4662</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-14.978</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I(horsepower ** 2)</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       coef  std err       t  P>|t|\n",
       "Intercept           56.9001    1.800  31.604    0.0\n",
       "horsepower          -0.4662    0.031 -14.978    0.0\n",
       "I(horsepower ** 2)   0.0012    0.000  10.080    0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.ols(formula = 'mpg ~ horsepower + I(horsepower**2)',\n",
    "                data = auto_df_no_gaps)\n",
    "fit = model.fit()\n",
    "\n",
    "results = fit.summary().tables[1]\n",
    "\n",
    "results_as_html = results.as_html()\n",
    "results_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "results_df[['coef', 'std err', 't', 'P>|t|']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42cb44-2396-47c3-b9ba-41b9da448a98",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

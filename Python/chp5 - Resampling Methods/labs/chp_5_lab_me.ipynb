{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa3ed09-da5c-4459-af7e-64c300ace29c",
   "metadata": {},
   "source": [
    "# 5.3 Lab: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "971b8db2-93b9-48d1-b7a1-532cd9eb8fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de60a8c-442a-4cf8-a098-1f4d43548616",
   "metadata": {},
   "source": [
    "## 5.3.1 The Validation Set Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc83c3f-29e6-459e-bfcd-34d8f6d66c0e",
   "metadata": {},
   "source": [
    "### Checking that training indices match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac918b6-fbd5-4a7c-b431-e68012c64811",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ISLR2)\n",
    "set.seed(1)\n",
    "train <- sort(sample(392, 196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ea3595-44ed-4c3b-816a-3a55aad1224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1]   1   9  13  14  15  16  17  19  20  22  24  25  29  30  31  33  36  37\n",
      " [19]  39  40  41  42  43  44  45  48  49  50  51  53  61  64  65  70  72  75\n",
      " [37]  77  78  79  80  84  85  86  88  89  92  93  98 102 103 104 105 106 107\n",
      " [55] 108 110 111 116 117 118 121 122 124 126 127 129 130 133 135 138 140 141\n",
      " [73] 143 145 149 152 157 159 160 163 164 165 167 170 172 174 176 181 185 187\n",
      " [91] 193 194 195 198 201 204 206 207 212 213 214 217 218 219 220 221 223 224\n",
      "[109] 225 228 229 230 233 234 237 238 239 240 242 244 246 247 248 252 255 258\n",
      "[127] 263 270 271 272 277 279 280 281 282 284 285 287 289 290 294 295 296 298\n",
      "[145] 299 304 306 307 309 310 313 315 318 319 323 324 325 326 328 329 330 331\n",
      "[163] 337 340 341 342 343 344 347 348 349 350 355 358 362 363 364 366 367 368\n",
      "[181] 369 372 373 374 375 376 378 382 383 384 386 388 389 390 391 392\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c183fb-bef6-4854-9edc-d36330912731",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robjects.r(\"\"\"\n",
    "library(ISLR2)\n",
    "set.seed(1)\n",
    "train <- sample(392, 196)\n",
    "\"\"\")\n",
    "\n",
    "train_idx = np.array(data)\n",
    "train_idx = np.sort(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b0cd6a5-8fed-420a-aeb0-845ff628404d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   9,  13,  14,  15,  16,  17,  19,  20,  22,  24,  25,  29,\n",
       "        30,  31,  33,  36,  37,  39,  40,  41,  42,  43,  44,  45,  48,\n",
       "        49,  50,  51,  53,  61,  64,  65,  70,  72,  75,  77,  78,  79,\n",
       "        80,  84,  85,  86,  88,  89,  92,  93,  98, 102, 103, 104, 105,\n",
       "       106, 107, 108, 110, 111, 116, 117, 118, 121, 122, 124, 126, 127,\n",
       "       129, 130, 133, 135, 138, 140, 141, 143, 145, 149, 152, 157, 159,\n",
       "       160, 163, 164, 165, 167, 170, 172, 174, 176, 181, 185, 187, 193,\n",
       "       194, 195, 198, 201, 204, 206, 207, 212, 213, 214, 217, 218, 219,\n",
       "       220, 221, 223, 224, 225, 228, 229, 230, 233, 234, 237, 238, 239,\n",
       "       240, 242, 244, 246, 247, 248, 252, 255, 258, 263, 270, 271, 272,\n",
       "       277, 279, 280, 281, 282, 284, 285, 287, 289, 290, 294, 295, 296,\n",
       "       298, 299, 304, 306, 307, 309, 310, 313, 315, 318, 319, 323, 324,\n",
       "       325, 326, 328, 329, 330, 331, 337, 340, 341, 342, 343, 344, 347,\n",
       "       348, 349, 350, 355, 358, 362, 363, 364, 366, 367, 368, 369, 372,\n",
       "       373, 374, 375, 376, 378, 382, 383, 384, 386, 388, 389, 390, 391,\n",
       "       392], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99669d0b-a1b9-4a40-8fa9-a392ee4f7ad3",
   "metadata": {},
   "source": [
    "Complete: Training indices match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68b583-80de-47d1-bd85-bf91d37b9b3f",
   "metadata": {},
   "source": [
    "### Checking that indexing in R and Python return same rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741719d6-876a-47f4-88b4-d3c7bd74dbab",
   "metadata": {},
   "source": [
    "#### Using .iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4bc67a-8168-417f-b123-f1974b65359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mpg cylinders displacement horsepower weight acceleration year origin\n",
      "1   18.0         8          307        130   3504         12.0   70      1\n",
      "9   14.0         8          455        225   4425         10.0   70      1\n",
      "13  15.0         8          400        150   3761          9.5   70      1\n",
      "14  14.0         8          455        225   3086         10.0   70      1\n",
      "15  24.0         4          113         95   2372         15.0   70      3\n",
      "16  22.0         6          198         95   2833         15.5   70      1\n",
      "17  18.0         6          199         97   2774         15.5   70      1\n",
      "19  27.0         4           97         88   2130         14.5   70      3\n",
      "20  26.0         4           97         46   1835         20.5   70      2\n",
      "22  24.0         4          107         90   2430         14.5   70      2\n",
      "24  26.0         4          121        113   2234         12.5   70      2\n",
      "25  21.0         6          199         90   2648         15.0   70      1\n",
      "29   9.0         8          304        193   4732         18.5   70      1\n",
      "30  27.0         4           97         88   2130         14.5   71      3\n",
      "31  28.0         4          140         90   2264         15.5   71      1\n",
      "34  19.0         6          232        100   2634         13.0   71      1\n",
      "37  19.0         6          250         88   3302         15.5   71      1\n",
      "38  18.0         6          232        100   3288         15.5   71      1\n",
      "40  14.0         8          400        175   4464         11.5   71      1\n",
      "41  14.0         8          351        153   4154         13.5   71      1\n",
      "42  14.0         8          318        150   4096         13.0   71      1\n",
      "43  12.0         8          383        180   4955         11.5   71      1\n",
      "44  13.0         8          400        170   4746         12.0   71      1\n",
      "45  13.0         8          400        175   5140         12.0   71      1\n",
      "46  18.0         6          258        110   2962         13.5   71      1\n",
      "49  18.0         6          250         88   3139         14.5   71      1\n",
      "50  23.0         4          122         86   2220         14.0   71      1\n",
      "51  28.0         4          116         90   2123         14.0   71      2\n",
      "52  30.0         4           79         70   2074         19.5   71      2\n",
      "54  31.0         4           71         65   1773         19.0   71      3\n",
      "62  21.0         4          122         86   2226         16.5   72      1\n",
      "65  15.0         8          318        150   4135         13.5   72      1\n",
      "66  14.0         8          351        153   4129         13.0   72      1\n",
      "71  13.0         8          400        190   4422         12.5   72      1\n",
      "73  15.0         8          304        150   3892         12.5   72      1\n",
      "76  14.0         8          318        150   4077         14.0   72      1\n",
      "78  22.0         4          121         76   2511         18.0   72      2\n",
      "79  21.0         4          120         87   2979         19.5   72      2\n",
      "80  26.0         4           96         69   2189         18.0   72      2\n",
      "81  22.0         4          122         86   2395         16.0   72      1\n",
      "85  27.0         4           97         88   2100         16.5   72      3\n",
      "86  13.0         8          350        175   4100         13.0   73      1\n",
      "87  14.0         8          304        150   3672         11.5   73      1\n",
      "89  14.0         8          302        137   4042         14.5   73      1\n",
      "90  15.0         8          318        150   3777         12.5   73      1\n",
      "93  13.0         8          351        158   4363         13.0   73      1\n",
      "94  14.0         8          318        150   4237         14.5   73      1\n",
      "99  16.0         6          250        100   3278         18.0   73      1\n",
      "103 26.0         4           97         46   1950         21.0   73      2\n",
      "104 11.0         8          400        150   4997         14.0   73      1\n",
      "105 12.0         8          400        167   4906         12.5   73      1\n",
      "106 13.0         8          360        170   4654         13.0   73      1\n",
      "107 12.0         8          350        180   4499         12.5   73      1\n",
      "108 18.0         6          232        100   2789         15.0   73      1\n",
      "109 20.0         4           97         88   2279         19.0   73      3\n",
      "111 22.0         4          108         94   2379         16.5   73      3\n",
      "112 18.0         3           70         90   2124         13.5   73      3\n",
      "117 16.0         8          400        230   4278          9.5   73      1\n",
      "118 29.0         4           68         49   1867         19.5   73      2\n",
      "119 24.0         4          116         75   2158         15.5   73      2\n",
      "122 15.0         8          318        150   3399         11.0   73      1\n",
      "123 24.0         4          121        110   2660         14.0   73      2\n",
      "125 11.0         8          350        180   3664         11.0   73      1\n",
      "128 19.0         6          232        100   2901         16.0   74      1\n",
      "129 15.0         6          250        100   3336         17.0   74      1\n",
      "131 26.0         4          122         80   2451         16.5   74      1\n",
      "132 32.0         4           71         65   1836         21.0   74      3\n",
      "135 16.0         6          258        110   3632         18.0   74      1\n",
      "137 16.0         8          302        140   4141         14.0   74      1\n",
      "140 14.0         8          302        140   4638         16.0   74      1\n",
      "142 29.0         4           98         83   2219         16.5   74      2\n",
      "143 26.0         4           79         67   1963         15.5   74      2\n",
      "145 31.0         4           76         52   1649         16.5   74      3\n",
      "147 28.0         4           90         75   2125         14.5   74      1\n",
      "151 26.0         4          108         93   2391         15.5   74      3\n",
      "154 18.0         6          250        105   3459         16.0   75      1\n",
      "159 16.0         8          318        150   4498         14.5   75      1\n",
      "161 17.0         6          231        110   3907         21.0   75      1\n",
      "162 16.0         6          250        105   3897         18.5   75      1\n",
      "165 21.0         6          231        110   3039         15.0   75      1\n",
      "166 20.0         8          262        110   3221         13.5   75      1\n",
      "167 13.0         8          302        129   3169         12.0   75      1\n",
      "169 23.0         4          140         83   2639         17.0   75      1\n",
      "172 24.0         4          134         96   2702         13.5   75      3\n",
      "174 24.0         4          119         97   2545         17.0   75      3\n",
      "176 29.0         4           90         70   1937         14.0   75      2\n",
      "178 23.0         4          115         95   2694         15.0   75      2\n",
      "183 28.0         4          107         86   2464         15.5   76      2\n",
      "187 27.0         4          101         83   2202         15.3   76      2\n",
      "189 16.0         8          318        150   4190         13.0   76      1\n",
      "195 22.5         6          232         90   3085         17.6   76      1\n",
      "196 29.0         4           85         52   2035         22.2   76      1\n",
      "197 24.5         4           98         60   2164         22.1   76      1\n",
      "200 20.0         6          225        100   3651         17.7   76      1\n",
      "203 17.5         6          258         95   3193         17.8   76      1\n",
      "206 28.0         4           97         75   2155         16.4   76      3\n",
      "208 20.0         4          130        102   3150         15.7   76      2\n",
      "209 13.0         8          318        150   3940         13.2   76      1\n",
      "214 13.0         8          350        145   4055         12.0   76      1\n",
      "215 13.0         8          302        130   3870         15.0   76      1\n",
      "216 13.0         8          318        150   3755         14.0   76      1\n",
      "219 36.0         4           79         58   1825         18.6   77      2\n",
      "220 25.5         4          122         96   2300         15.5   77      1\n",
      "221 33.5         4           85         70   1945         16.8   77      3\n",
      "222 17.5         8          305        145   3880         12.5   77      1\n",
      "223 17.0         8          260        110   4060         19.0   77      1\n",
      "225 15.0         8          302        130   4295         14.9   77      1\n",
      "226 17.5         6          250        110   3520         16.4   77      1\n",
      "227 20.5         6          231        105   3425         16.9   77      1\n",
      "230 16.0         8          400        180   4220         11.1   77      1\n",
      "231 15.5         8          350        170   4165         11.4   77      1\n",
      "232 15.5         8          400        190   4325         12.2   77      1\n",
      "235 24.5         4          151         88   2740         16.0   77      1\n",
      "236 26.0         4           97         75   2265         18.2   77      3\n",
      "239 33.5         4           98         83   2075         15.9   77      1\n",
      "240 30.0         4           97         67   1985         16.4   77      3\n",
      "241 30.5         4           97         78   2190         14.1   77      2\n",
      "242 22.0         6          146         97   2815         14.5   77      3\n",
      "244 21.5         3           80        110   2720         13.5   77      3\n",
      "246 36.1         4           98         66   1800         14.4   78      1\n",
      "248 39.4         4           85         70   2070         18.6   78      3\n",
      "249 36.1         4           91         60   1800         16.4   78      3\n",
      "250 19.9         8          260        110   3365         15.5   78      1\n",
      "254 20.5         6          200         95   3155         18.2   78      1\n",
      "257 20.5         6          225        100   3430         17.2   78      1\n",
      "260 20.8         6          200         85   3070         16.7   78      1\n",
      "265 18.1         8          302        139   3205         11.2   78      1\n",
      "272 23.2         4          156        105   2745         16.7   78      1\n",
      "273 23.8         4          151         85   2855         17.6   78      1\n",
      "274 23.9         4          119         97   2405         14.9   78      3\n",
      "279 31.5         4           89         71   1990         14.9   78      2\n",
      "281 21.5         6          231        115   3245         15.4   79      1\n",
      "282 19.8         6          200         85   2990         18.2   79      1\n",
      "283 22.3         4          140         88   2890         17.3   79      1\n",
      "284 20.2         6          232         90   3265         18.2   79      1\n",
      "286 17.0         8          305        130   3840         15.4   79      1\n",
      "287 17.6         8          302        129   3725         13.4   79      1\n",
      "289 18.2         8          318        135   3830         15.2   79      1\n",
      "291 15.5         8          351        142   4054         14.3   79      1\n",
      "292 19.2         8          267        125   3605         15.0   79      1\n",
      "296 35.7         4           98         80   1915         14.4   79      1\n",
      "297 27.4         4          121         80   2670         15.0   79      1\n",
      "298 25.4         5          183         77   3530         20.1   79      2\n",
      "300 27.2         4          141         71   3190         24.8   79      2\n",
      "301 23.9         8          260         90   3420         22.2   79      1\n",
      "306 28.4         4          151         90   2670         16.0   79      1\n",
      "308 26.8         6          173        115   2700         12.9   79      1\n",
      "309 33.5         4          151         90   2556         13.2   79      1\n",
      "311 38.1         4           89         60   1968         18.8   80      3\n",
      "312 32.1         4           98         70   2120         15.5   80      1\n",
      "315 26.4         4          140         88   2870         18.1   80      1\n",
      "317 19.1         6          225         90   3381         18.7   80      1\n",
      "320 31.3         4          120         75   2542         17.5   80      3\n",
      "321 37.0         4          119         92   2434         15.0   80      3\n",
      "325 40.8         4           85         65   2110         19.2   80      3\n",
      "326 44.3         4           90         48   2085         21.7   80      2\n",
      "327 43.4         4           90         48   2335         23.7   80      2\n",
      "328 36.4         5          121         67   2950         19.9   80      2\n",
      "330 44.6         4           91         67   1850         13.8   80      3\n",
      "332 33.8         4           97         67   2145         18.0   80      3\n",
      "333 29.8         4           89         62   1845         15.3   80      2\n",
      "334 32.7         6          168        132   2910         11.4   80      3\n",
      "341 25.8         4          156         92   2620         14.4   81      1\n",
      "344 39.1         4           79         58   1755         16.9   81      3\n",
      "345 39.0         4           86         64   1875         16.4   81      1\n",
      "346 35.1         4           81         60   1760         16.1   81      3\n",
      "347 32.3         4           97         67   2065         17.8   81      3\n",
      "348 37.0         4           85         65   1975         19.4   81      3\n",
      "351 34.7         4          105         63   2215         14.9   81      1\n",
      "352 34.4         4           98         65   2045         16.2   81      1\n",
      "353 29.9         4           98         65   2380         20.7   81      1\n",
      "354 33.0         4          105         74   2190         14.2   81      2\n",
      "360 28.1         4          141         80   3230         20.4   81      2\n",
      "363 24.2         6          146        120   2930         13.8   81      3\n",
      "367 17.6         6          225         85   3465         16.6   81      1\n",
      "368 28.0         4          112         88   2605         19.6   82      1\n",
      "369 27.0         4          112         88   2640         18.6   82      1\n",
      "371 31.0         4          112         85   2575         16.2   82      1\n",
      "372 29.0         4          135         84   2525         16.0   82      1\n",
      "373 27.0         4          151         90   2735         18.0   82      1\n",
      "374 24.0         4          140         92   2865         16.4   82      1\n",
      "377 31.0         4           91         68   1970         17.6   82      3\n",
      "378 38.0         4          105         63   2125         14.7   82      1\n",
      "379 36.0         4           98         70   2125         17.3   82      1\n",
      "380 36.0         4          120         88   2160         14.5   82      3\n",
      "381 36.0         4          107         75   2205         14.5   82      3\n",
      "383 38.0         4           91         67   1965         15.0   82      3\n",
      "387 38.0         6          262         85   3015         17.0   82      1\n",
      "388 26.0         4          156         92   2585         14.5   82      1\n",
      "389 22.0         6          232        112   2835         14.7   82      1\n",
      "391 36.0         4          135         84   2370         13.0   82      1\n",
      "393 27.0         4          140         86   2790         15.6   82      1\n",
      "394 44.0         4           97         52   2130         24.6   82      2\n",
      "395 32.0         4          135         84   2295         11.6   82      1\n",
      "396 28.0         4          120         79   2625         18.6   82      1\n",
      "397 31.0         4          119         82   2720         19.4   82      1\n",
      "                                 name\n",
      "1           chevrolet chevelle malibu\n",
      "9                    pontiac catalina\n",
      "13              chevrolet monte carlo\n",
      "14            buick estate wagon (sw)\n",
      "15              toyota corona mark ii\n",
      "16                    plymouth duster\n",
      "17                         amc hornet\n",
      "19                       datsun pl510\n",
      "20       volkswagen 1131 deluxe sedan\n",
      "22                        audi 100 ls\n",
      "24                           bmw 2002\n",
      "25                        amc gremlin\n",
      "29                           hi 1200d\n",
      "30                       datsun pl510\n",
      "31                chevrolet vega 2300\n",
      "34                        amc gremlin\n",
      "37                    ford torino 500\n",
      "38                        amc matador\n",
      "40          pontiac catalina brougham\n",
      "41                   ford galaxie 500\n",
      "42                  plymouth fury iii\n",
      "43                  dodge monaco (sw)\n",
      "44           ford country squire (sw)\n",
      "45                pontiac safari (sw)\n",
      "46         amc hornet sportabout (sw)\n",
      "49                       ford mustang\n",
      "50                 mercury capri 2000\n",
      "51                          opel 1900\n",
      "52                        peugeot 304\n",
      "54                toyota corolla 1200\n",
      "62                ford pinto runabout\n",
      "65                  plymouth fury iii\n",
      "66                   ford galaxie 500\n",
      "71             chrysler newport royal\n",
      "73                   amc matador (sw)\n",
      "76     plymouth satellite custom (sw)\n",
      "78                volkswagen 411 (sw)\n",
      "79                   peugeot 504 (sw)\n",
      "80                    renault 12 (sw)\n",
      "81                    ford pinto (sw)\n",
      "85           toyota corolla 1600 (sw)\n",
      "86                  buick century 350\n",
      "87                        amc matador\n",
      "89                   ford gran torino\n",
      "90               dodge coronet custom\n",
      "93                           ford ltd\n",
      "94           plymouth fury gran sedan\n",
      "99              chevrolet nova custom\n",
      "103           volkswagen super beetle\n",
      "104                  chevrolet impala\n",
      "105                      ford country\n",
      "106            plymouth custom suburb\n",
      "107          oldsmobile vista cruiser\n",
      "108                       amc gremlin\n",
      "109                     toyota carina\n",
      "111                        datsun 610\n",
      "112                         maxda rx3\n",
      "117                pontiac grand prix\n",
      "118                          fiat 128\n",
      "119                        opel manta\n",
      "122                 dodge dart custom\n",
      "123                         saab 99le\n",
      "125                  oldsmobile omega\n",
      "128                        amc hornet\n",
      "129                    chevrolet nova\n",
      "131                        ford pinto\n",
      "132               toyota corolla 1200\n",
      "135                       amc matador\n",
      "137                  ford gran torino\n",
      "140             ford gran torino (sw)\n",
      "142                          audi fox\n",
      "143                 volkswagen dasher\n",
      "145                     toyota corona\n",
      "147                        dodge colt\n",
      "151                            subaru\n",
      "154                    chevrolet nova\n",
      "159               plymouth grand fury\n",
      "161                     buick century\n",
      "162         chevroelt chevelle malibu\n",
      "165                     buick skyhawk\n",
      "166               chevrolet monza 2+2\n",
      "167                   ford mustang ii\n",
      "169                        ford pinto\n",
      "172                     toyota corona\n",
      "174                        datsun 710\n",
      "176                 volkswagen rabbit\n",
      "178                        audi 100ls\n",
      "183                          fiat 131\n",
      "187                      renault 12tl\n",
      "189            dodge coronet brougham\n",
      "195                        amc hornet\n",
      "196                chevrolet chevette\n",
      "197                   chevrolet woody\n",
      "200                    dodge aspen se\n",
      "203                     amc pacer d/l\n",
      "206                    toyota corolla\n",
      "208                         volvo 245\n",
      "209        plymouth volare premier v8\n",
      "214                         chevy c10\n",
      "215                         ford f108\n",
      "216                        dodge d100\n",
      "219                     renault 5 gtl\n",
      "220                 plymouth arrow gs\n",
      "221             datsun f-10 hatchback\n",
      "222         chevrolet caprice classic\n",
      "223        oldsmobile cutlass supreme\n",
      "225           mercury cougar brougham\n",
      "226                chevrolet concours\n",
      "227                     buick skylark\n",
      "230             pontiac grand prix lj\n",
      "231      chevrolet monte carlo landau\n",
      "232                  chrysler cordoba\n",
      "235             pontiac sunbird coupe\n",
      "236           toyota corolla liftback\n",
      "239                    dodge colt m/m\n",
      "240                         subaru dl\n",
      "241                 volkswagen dasher\n",
      "242                        datsun 810\n",
      "244                        mazda rx-4\n",
      "246                       ford fiesta\n",
      "248                    datsun b210 gx\n",
      "249                  honda civic cvcc\n",
      "250 oldsmobile cutlass salon brougham\n",
      "254                  chevrolet malibu\n",
      "257                   plymouth volare\n",
      "260                    mercury zephyr\n",
      "265                       ford futura\n",
      "272                  plymouth sapporo\n",
      "273            oldsmobile starfire sx\n",
      "274                     datsun 200-sx\n",
      "279               volkswagen scirocco\n",
      "281                 pontiac lemans v6\n",
      "282                  mercury zephyr 6\n",
      "283                   ford fairmont 4\n",
      "284                  amc concord dl 6\n",
      "286         chevrolet caprice classic\n",
      "287                   ford ltd landau\n",
      "289                   dodge st. regis\n",
      "291          ford country squire (sw)\n",
      "292     chevrolet malibu classic (sw)\n",
      "296       dodge colt hatchback custom\n",
      "297                     amc spirit dl\n",
      "298                mercedes benz 300d\n",
      "300                       peugeot 504\n",
      "301 oldsmobile cutlass salon brougham\n",
      "306             buick skylark limited\n",
      "308         oldsmobile omega brougham\n",
      "309                   pontiac phoenix\n",
      "311             toyota corolla tercel\n",
      "312                chevrolet chevette\n",
      "315                     ford fairmont\n",
      "317                       dodge aspen\n",
      "320                         mazda 626\n",
      "321              datsun 510 hatchback\n",
      "325                        datsun 210\n",
      "326              vw rabbit c (diesel)\n",
      "327                vw dasher (diesel)\n",
      "328               audi 5000s (diesel)\n",
      "330               honda civic 1500 gl\n",
      "332                         subaru dl\n",
      "333                  vokswagen rabbit\n",
      "334                     datsun 280-zx\n",
      "341            dodge aries wagon (sw)\n",
      "344                    toyota starlet\n",
      "345                    plymouth champ\n",
      "346                  honda civic 1300\n",
      "347                            subaru\n",
      "348                    datsun 210 mpg\n",
      "351                plymouth horizon 4\n",
      "352                    ford escort 4w\n",
      "353                    ford escort 2h\n",
      "354                  volkswagen jetta\n",
      "360         peugeot 505s turbo diesel\n",
      "363                 datsun 810 maxima\n",
      "367            chrysler lebaron salon\n",
      "368                chevrolet cavalier\n",
      "369          chevrolet cavalier wagon\n",
      "371        pontiac j2000 se hatchback\n",
      "372                    dodge aries se\n",
      "373                   pontiac phoenix\n",
      "374              ford fairmont futura\n",
      "377                  mazda glc custom\n",
      "378            plymouth horizon miser\n",
      "379                    mercury lynx l\n",
      "380                  nissan stanza xe\n",
      "381                      honda accord\n",
      "383                       honda civic\n",
      "387 oldsmobile cutlass ciera (diesel)\n",
      "388        chrysler lebaron medallion\n",
      "389                    ford granada l\n",
      "391                 dodge charger 2.2\n",
      "393                   ford mustang gl\n",
      "394                         vw pickup\n",
      "395                     dodge rampage\n",
      "396                       ford ranger\n",
      "397                        chevy s-10\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "Auto[sort(train), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07abd7e2-9aad-4bf2-9ba0-ca96be169846",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = pd.read_csv(\"../../../datasets/Auto.csv\", na_values='?')\n",
    "\n",
    "# Reset index labels to start at 1 to match R's behavior\n",
    "auto_df = auto_df.set_index(keys=np.arange(1, len(auto_df) + 1))\n",
    "\n",
    "# Drow rows that contain '?' values that represent na values\n",
    "auto_df = auto_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b171cafe-0fce-4e1d-a213-5b94785760ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "397  31.0          4         119.0        82.0    2720          19.4    82   \n",
       "\n",
       "     origin        name  \n",
       "397       1  chevy s-10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_df[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81fc83-a252-4849-8b6c-04a6b923177f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afbbee55-f135-459c-8e89-e0136bf8d845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg                   31.0\n",
       "cylinders                4\n",
       "displacement         119.0\n",
       "horsepower            82.0\n",
       "weight                2720\n",
       "acceleration          19.4\n",
       "year                    82\n",
       "origin                   1\n",
       "name            chevy s-10\n",
       "Name: 397, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .loc uses index labels to access rows from the dataframe.  Because auto_df originally had 397 rows, before dropping na values, the rows were labelled 1-397.\n",
    "auto_df.loc[397]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526cf3d9-948f-481b-8fc7-7d87c358aa08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg                   31.0\n",
       "cylinders                4\n",
       "displacement         119.0\n",
       "horsepower            82.0\n",
       "weight                2720\n",
       "acceleration          19.4\n",
       "year                    82\n",
       "origin                   1\n",
       "name            chevy s-10\n",
       "Name: 397, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .iloc uses integer labels to access rows from the dataframe.  After dropping the 5 na values from auto_df, there are only 392 rows remaining.  These rows have integer labels ranging from 0 (first row) to 391 (last row).  Indexing in R behaves like .iloc in that it uses integer labels.  This is why sample(392, 196) was used in generating the training index labels in R, there are 392 rows in the dataframe to sample from.\n",
    "auto_df.iloc[392 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf464eb3-11d5-40c3-8339-c2d0bb56f942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>pontiac catalina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet monte carlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick estate wagon (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corona mark ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "1    18.0          8         307.0       130.0    3504          12.0    70   \n",
       "9    14.0          8         455.0       225.0    4425          10.0    70   \n",
       "13   15.0          8         400.0       150.0    3761           9.5    70   \n",
       "14   14.0          8         455.0       225.0    3086          10.0    70   \n",
       "15   24.0          4         113.0        95.0    2372          15.0    70   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "393  27.0          4         140.0        86.0    2790          15.6    82   \n",
       "394  44.0          4          97.0        52.0    2130          24.6    82   \n",
       "395  32.0          4         135.0        84.0    2295          11.6    82   \n",
       "396  28.0          4         120.0        79.0    2625          18.6    82   \n",
       "397  31.0          4         119.0        82.0    2720          19.4    82   \n",
       "\n",
       "     origin                       name  \n",
       "1         1  chevrolet chevelle malibu  \n",
       "9         1           pontiac catalina  \n",
       "13        1      chevrolet monte carlo  \n",
       "14        1    buick estate wagon (sw)  \n",
       "15        3      toyota corona mark ii  \n",
       "..      ...                        ...  \n",
       "393       1            ford mustang gl  \n",
       "394       2                  vw pickup  \n",
       "395       1              dodge rampage  \n",
       "396       1                ford ranger  \n",
       "397       1                 chevy s-10  \n",
       "\n",
       "[196 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using subtracting 1 from train_idx ensures the labels generated in R, which go from 1-392, now range from 0-391 so they work in P\n",
    "auto_df.iloc[train_idx-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7a430-7549-41f8-8296-d4a428fd6cf1",
   "metadata": {},
   "source": [
    "Complete: same rows are returned using the training indices using .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5526e50-058b-4d80-865c-311c28c085c0",
   "metadata": {},
   "source": [
    "#### Using a boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c508f122-4b71-4852-b238-6a1e08a0e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since boolean masks work using integer labels for indexing, this approach also can be used instead of .iloc, and it might be preferred since it's much easier to get the testing indices by negating the training indices.\n",
    "\n",
    "auto_df_no_gaps = auto_df.copy(deep=True)\n",
    "\n",
    "auto_df_no_gaps= auto_df_no_gaps.set_index(np.arange(1, auto_df_no_gaps.shape[0] + 1))\n",
    "\n",
    "auto_train_mask_no_gaps = auto_df_no_gaps.index.isin(train_idx)\n",
    "\n",
    "auto_test_maks_no_gaps = ~auto_train_mask_no_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d01fbf4-77dc-4310-8140-8bf17b92c245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>pontiac catalina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet monte carlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick estate wagon (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corona mark ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "1    18.0          8         307.0       130.0    3504          12.0    70   \n",
       "9    14.0          8         455.0       225.0    4425          10.0    70   \n",
       "13   15.0          8         400.0       150.0    3761           9.5    70   \n",
       "14   14.0          8         455.0       225.0    3086          10.0    70   \n",
       "15   24.0          4         113.0        95.0    2372          15.0    70   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "388  27.0          4         140.0        86.0    2790          15.6    82   \n",
       "389  44.0          4          97.0        52.0    2130          24.6    82   \n",
       "390  32.0          4         135.0        84.0    2295          11.6    82   \n",
       "391  28.0          4         120.0        79.0    2625          18.6    82   \n",
       "392  31.0          4         119.0        82.0    2720          19.4    82   \n",
       "\n",
       "     origin                       name  \n",
       "1         1  chevrolet chevelle malibu  \n",
       "9         1           pontiac catalina  \n",
       "13        1      chevrolet monte carlo  \n",
       "14        1    buick estate wagon (sw)  \n",
       "15        3      toyota corona mark ii  \n",
       "..      ...                        ...  \n",
       "388       1            ford mustang gl  \n",
       "389       2                  vw pickup  \n",
       "390       1              dodge rampage  \n",
       "391       1                ford ranger  \n",
       "392       1                 chevy s-10  \n",
       "\n",
       "[196 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_df_no_gaps[auto_train_mask_no_gaps]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1caba-f79a-4a76-ab97-31bb27de4138",
   "metadata": {},
   "source": [
    "Complete: boolean index returns same rows in Python and R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65c56b-d80e-4051-a96d-f49c995f87a4",
   "metadata": {},
   "source": [
    "### Checking that lm and smf.ols produce same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e84c8c11-7ec3-425d-8ca0-cd64735a382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "107da2c7-6d3b-4466-bf18-b5020565c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = mpg ~ horsepower, data = Auto, subset = train)\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median      3Q     Max \n",
      "-9.3177 -3.5428 -0.5591  2.3910 14.6836 \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept) 41.283548   1.044352   39.53   <2e-16 ***\n",
      "horsepower  -0.169659   0.009556  -17.75   <2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n",
      "\n",
      "Residual standard error: 5.032 on 194 degrees of freedom\n",
      "Multiple R-squared:  0.619,\tAdjusted R-squared:  0.6171 \n",
      "F-statistic: 315.2 on 1 and 194 DF,  p-value: < 2.2e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary(lm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "123e0bce-e2e7-449c-aa35-81f333e93c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model = smf.ols(formula = 'mpg ~ horsepower', data = auto_df.iloc[train_idx-1])\n",
    "lm_fit = lm_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e12616b-e579-44b4-9c99-b98bdd1be9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   315.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>1.61e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:40:10</td>     <th>  Log-Likelihood:    </th> <td> -593.80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1192.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   194</td>      <th>  BIC:               </th> <td>   1198.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   41.2835</td> <td>    1.044</td> <td>   39.530</td> <td> 0.000</td> <td>   39.224</td> <td>   43.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   -0.1697</td> <td>    0.010</td> <td>  -17.754</td> <td> 0.000</td> <td>   -0.189</td> <td>   -0.151</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.451</td> <th>  Durbin-Watson:     </th> <td>   1.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  14.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.662</td> <th>  Prob(JB):          </th> <td>0.000714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.149</td> <th>  Cond. No.          </th> <td>    318.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.619\n",
       "Model:                            OLS   Adj. R-squared:                  0.617\n",
       "Method:                 Least Squares   F-statistic:                     315.2\n",
       "Date:                Sat, 21 Jan 2023   Prob (F-statistic):           1.61e-42\n",
       "Time:                        18:40:10   Log-Likelihood:                -593.80\n",
       "No. Observations:                 196   AIC:                             1192.\n",
       "Df Residuals:                     194   BIC:                             1198.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     41.2835      1.044     39.530      0.000      39.224      43.343\n",
       "horsepower    -0.1697      0.010    -17.754      0.000      -0.189      -0.151\n",
       "==============================================================================\n",
       "Omnibus:                       13.451   Durbin-Watson:                   1.171\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.488\n",
       "Skew:                           0.662   Prob(JB):                     0.000714\n",
       "Kurtosis:                       3.149   Cond. No.                         318.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dac52f-f77b-419e-b03c-418b2120ffe1",
   "metadata": {},
   "source": [
    "Complete: R's lm function and Python's smf.ols return the same model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e4d57-8917-40b8-895f-85c4eb961fcc",
   "metadata": {},
   "source": [
    "### Creating test indices for Python and checking that same rows are returned in R and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f887c8c4-2a1d-4a50-b83c-2787c4e1e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mpg                                 name\n",
      "2   15.0                    buick skylark 320\n",
      "3   18.0                   plymouth satellite\n",
      "4   16.0                        amc rebel sst\n",
      "5   17.0                          ford torino\n",
      "6   15.0                     ford galaxie 500\n",
      "7   14.0                     chevrolet impala\n",
      "8   14.0                    plymouth fury iii\n",
      "10  15.0                   amc ambassador dpl\n",
      "11  15.0                  dodge challenger se\n",
      "12  14.0                   plymouth 'cuda 340\n",
      "18  21.0                        ford maverick\n",
      "21  25.0                          peugeot 504\n",
      "23  25.0                             saab 99e\n",
      "26  10.0                            ford f250\n",
      "27  10.0                            chevy c20\n",
      "28  11.0                           dodge d200\n",
      "32  25.0                        toyota corona\n",
      "35  16.0            plymouth satellite custom\n",
      "36  17.0            chevrolet chevelle malibu\n",
      "39  14.0                     chevrolet impala\n",
      "47  22.0                  chevrolet vega (sw)\n",
      "48  19.0                     pontiac firebird\n",
      "53  30.0                            fiat 124b\n",
      "55  35.0                          datsun 1200\n",
      "56  27.0                 volkswagen model 111\n",
      "57  26.0                     plymouth cricket\n",
      "58  24.0                toyota corona hardtop\n",
      "59  25.0                   dodge colt hardtop\n",
      "60  23.0                    volkswagen type 3\n",
      "61  20.0                       chevrolet vega\n",
      "63  13.0                     chevrolet impala\n",
      "64  14.0                     pontiac catalina\n",
      "67  17.0                   amc ambassador sst\n",
      "68  11.0                      mercury marquis\n",
      "69  13.0                 buick lesabre custom\n",
      "70  12.0           oldsmobile delta 88 royale\n",
      "72  19.0                      mazda rx2 coupe\n",
      "74  13.0     chevrolet chevelle concours (sw)\n",
      "75  13.0                ford gran torino (sw)\n",
      "77  18.0                      volvo 145e (sw)\n",
      "82  28.0                      datsun 510 (sw)\n",
      "83  23.0          toyouta corona mark ii (sw)\n",
      "84  28.0                      dodge colt (sw)\n",
      "88  13.0                     chevrolet malibu\n",
      "91  12.0             mercury marquis brougham\n",
      "92  13.0            chevrolet caprice classic\n",
      "95  13.0         chrysler new yorker brougham\n",
      "96  12.0             buick electra 225 custom\n",
      "97  13.0              amc ambassador brougham\n",
      "98  18.0                     plymouth valiant\n",
      "100 18.0                           amc hornet\n",
      "101 18.0                        ford maverick\n",
      "102 23.0                      plymouth duster\n",
      "110 21.0                       chevrolet vega\n",
      "113 19.0                           ford pinto\n",
      "114 21.0                     mercury capri v6\n",
      "115 26.0                 fiat 124 sport coupe\n",
      "116 15.0              chevrolet monte carlo s\n",
      "120 20.0                           audi 100ls\n",
      "121 19.0                          volvo 144ea\n",
      "124 20.0                       toyota mark ii\n",
      "126 20.0                      plymouth duster\n",
      "130 31.0                          datsun b210\n",
      "133 25.0                       chevrolet vega\n",
      "134 16.0    chevrolet chevelle malibu classic\n",
      "136 18.0           plymouth satellite sebring\n",
      "138 13.0             buick century luxus (sw)\n",
      "139 14.0            dodge coronet custom (sw)\n",
      "141 14.0                     amc matador (sw)\n",
      "144 26.0                           opel manta\n",
      "146 32.0                           datsun 710\n",
      "148 24.0                             fiat 128\n",
      "149 26.0                          fiat 124 tc\n",
      "150 24.0                          honda civic\n",
      "152 31.0                            fiat x1.9\n",
      "153 19.0              plymouth valiant custom\n",
      "155 15.0                      mercury monarch\n",
      "156 15.0                        ford maverick\n",
      "157 16.0                     pontiac catalina\n",
      "158 15.0                    chevrolet bel air\n",
      "160 14.0                             ford ltd\n",
      "163 15.0                          amc matador\n",
      "164 18.0                        plymouth fury\n",
      "168 29.0                       toyota corolla\n",
      "170 20.0                          amc gremlin\n",
      "171 23.0                        pontiac astro\n",
      "173 25.0                    volkswagen dasher\n",
      "175 18.0                           ford pinto\n",
      "177 19.0                            amc pacer\n",
      "179 23.0                          peugeot 504\n",
      "180 22.0                          volvo 244dl\n",
      "181 25.0                            saab 99le\n",
      "182 33.0                     honda civic cvcc\n",
      "184 25.0                            opel 1900\n",
      "185 25.0                             capri ii\n",
      "186 26.0                           dodge colt\n",
      "188 17.5    chevrolet chevelle malibu classic\n",
      "190 15.5                          amc matador\n",
      "191 14.5                     ford gran torino\n",
      "192 22.0                     plymouth valiant\n",
      "193 22.0                       chevrolet nova\n",
      "194 24.0                        ford maverick\n",
      "198 29.0                            vw rabbit\n",
      "199 33.0                          honda civic\n",
      "201 18.0                    ford granada ghia\n",
      "202 18.5                   pontiac ventura sj\n",
      "204 29.5                    volkswagen rabbit\n",
      "205 32.0                         datsun b-210\n",
      "207 26.5                           ford pinto\n",
      "210 19.0                          peugeot 504\n",
      "211 19.0                       toyota mark ii\n",
      "212 16.5                   mercedes-benz 280s\n",
      "213 16.5                     cadillac seville\n",
      "217 31.5                    honda accord cvcc\n",
      "218 30.0              buick opel isuzu deluxe\n",
      "224 15.5                dodge monaco brougham\n",
      "228 19.0               plymouth volare custom\n",
      "229 18.5                         ford granada\n",
      "233 16.0                     ford thunderbird\n",
      "234 29.0             volkswagen rabbit custom\n",
      "237 25.5                  ford mustang ii 2+2\n",
      "238 30.5                   chevrolet chevette\n",
      "243 21.5                             bmw 320i\n",
      "245 43.1      volkswagen rabbit custom diesel\n",
      "247 32.8                     mazda glc deluxe\n",
      "251 19.4                       dodge diplomat\n",
      "252 20.2                 mercury monarch ghia\n",
      "253 19.2                   pontiac phoenix lj\n",
      "255 20.2                 ford fairmont (auto)\n",
      "256 25.1                  ford fairmont (man)\n",
      "258 19.4                          amc concord\n",
      "259 20.6                buick century special\n",
      "261 18.6                          dodge aspen\n",
      "262 18.1                      amc concord d/l\n",
      "263 19.2         chevrolet monte carlo landau\n",
      "264 17.7      buick regal sport coupe (turbo)\n",
      "266 17.5                      dodge magnum xe\n",
      "267 30.0                   chevrolet chevette\n",
      "268 27.5                        toyota corona\n",
      "269 27.2                           datsun 510\n",
      "270 30.9                           dodge omni\n",
      "271 21.1            toyota celica gt liftback\n",
      "275 20.3                            audi 5000\n",
      "276 17.0                          volvo 264gl\n",
      "277 21.6                           saab 99gle\n",
      "278 16.2                        peugeot 604sl\n",
      "280 29.5                      honda accord lx\n",
      "285 20.6                        dodge aspen 6\n",
      "288 16.5                mercury grand marquis\n",
      "290 16.9              buick estate wagon (sw)\n",
      "293 18.5 chrysler lebaron town @ country (sw)\n",
      "294 31.9                     vw rabbit custom\n",
      "295 34.1                     maxda glc deluxe\n",
      "299 23.0                    cadillac eldorado\n",
      "302 34.2                     plymouth horizon\n",
      "303 34.5                 plymouth horizon tc3\n",
      "304 31.8                           datsun 210\n",
      "305 37.3                   fiat strada custom\n",
      "307 28.8                   chevrolet citation\n",
      "310 41.5                            vw rabbit\n",
      "313 37.2                           datsun 310\n",
      "314 28.0                   chevrolet citation\n",
      "316 24.3                          amc concord\n",
      "318 34.3                            audi 4000\n",
      "319 29.8               toyota corona liftback\n",
      "322 32.2                       toyota corolla\n",
      "323 46.6                            mazda glc\n",
      "324 27.9                           dodge colt\n",
      "329 30.0                   mercedes-benz 240d\n",
      "335 23.7                        mazda rx-7 gs\n",
      "336 35.0                    triumph tr7 coupe\n",
      "338 32.4                         honda accord\n",
      "339 27.2                     plymouth reliant\n",
      "340 26.6                        buick skylark\n",
      "342 23.5                   chevrolet citation\n",
      "343 30.0                     plymouth reliant\n",
      "349 37.7                        toyota tercel\n",
      "350 34.1                          mazda glc 4\n",
      "356 33.7                        honda prelude\n",
      "357 32.4                       toyota corolla\n",
      "358 32.9                         datsun 200sx\n",
      "359 31.6                            mazda 626\n",
      "361 30.7                         volvo diesel\n",
      "362 25.4                      toyota cressida\n",
      "364 22.4                        buick century\n",
      "365 26.6                oldsmobile cutlass ls\n",
      "366 20.2                      ford granada gl\n",
      "370 34.0            chevrolet cavalier 2-door\n",
      "375 36.0                  volkswagen rabbit l\n",
      "376 37.0                   mazda glc custom l\n",
      "382 34.0                       toyota corolla\n",
      "384 32.0                   honda civic (auto)\n",
      "385 38.0                        datsun 310 gx\n",
      "386 25.0                buick century limited\n",
      "390 32.0                     toyota celica gt\n",
      "392 27.0                     chevrolet camaro\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "Auto[-train, c(1,9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b34fa-e065-46d0-9e9c-6ce2e96487dc",
   "metadata": {},
   "source": [
    "#### Using .iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3420fbc-d180-4a7c-a754-dbfd40a110a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because R using integer index labels when doing stuff like Auto[train, ], we need to use .iloc on our df in Python to copy the behavior.  Using .set_index, changes row labels, but not integer labels, and the integer labels always begin at 0, so we use np.arange(0, 392) to produce the indices 0 to 391, for the 392 entries in the auto_df.  Next, because train_idx is the list of integer row labels from R, which begins integer labels at 1, we need to subtract 1 from each entry to match the row integer labels in Python.  Using the set() function allows us to find the set difference, or the integer indices for rows not in our training set.  Because the set difference returns a set, which is treated as a single element, we can't use it with .iloc to get the rows we want, instead we convert the set to a list first.\n",
    "test_idx = list(set(np.arange(0,392)) - set(train_idx-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23422848-975b-426d-a2ee-f16568b89384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford galaxie 500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>15.7</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>honda civic (auto)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>datsun 310 gx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>181.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2945</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>buick century limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>144.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2665</td>\n",
       "      <td>13.9</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota celica gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2950</td>\n",
       "      <td>17.3</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet camaro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "2    15.0          8         350.0       165.0    3693          11.5    70   \n",
       "3    18.0          8         318.0       150.0    3436          11.0    70   \n",
       "4    16.0          8         304.0       150.0    3433          12.0    70   \n",
       "5    17.0          8         302.0       140.0    3449          10.5    70   \n",
       "6    15.0          8         429.0       198.0    4341          10.0    70   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "384  32.0          4          91.0        67.0    1965          15.7    82   \n",
       "385  38.0          4          91.0        67.0    1995          16.2    82   \n",
       "386  25.0          6         181.0       110.0    2945          16.4    82   \n",
       "390  32.0          4         144.0        96.0    2665          13.9    82   \n",
       "392  27.0          4         151.0        90.0    2950          17.3    82   \n",
       "\n",
       "     origin                   name  \n",
       "2         1      buick skylark 320  \n",
       "3         1     plymouth satellite  \n",
       "4         1          amc rebel sst  \n",
       "5         1            ford torino  \n",
       "6         1       ford galaxie 500  \n",
       "..      ...                    ...  \n",
       "384       3     honda civic (auto)  \n",
       "385       3          datsun 310 gx  \n",
       "386       1  buick century limited  \n",
       "390       3       toyota celica gt  \n",
       "392       1       chevrolet camaro  \n",
       "\n",
       "[196 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_df.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5a22d9-6246-4ec4-94a7-5d7d7bd5276b",
   "metadata": {},
   "source": [
    "Complete: test indices return the same rows in R and Python using .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e15af10-9a9a-4114-9fdf-0596106076a0",
   "metadata": {},
   "source": [
    "#### Using boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5501739d-ea7f-441e-820a-680e07683b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford galaxie 500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>15.7</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>honda civic (auto)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>datsun 310 gx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>181.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2945</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>buick century limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>144.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2665</td>\n",
       "      <td>13.9</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota celica gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2950</td>\n",
       "      <td>17.3</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet camaro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "2    15.0          8         350.0       165.0    3693          11.5    70   \n",
       "3    18.0          8         318.0       150.0    3436          11.0    70   \n",
       "4    16.0          8         304.0       150.0    3433          12.0    70   \n",
       "5    17.0          8         302.0       140.0    3449          10.5    70   \n",
       "6    15.0          8         429.0       198.0    4341          10.0    70   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "384  32.0          4          91.0        67.0    1965          15.7    82   \n",
       "385  38.0          4          91.0        67.0    1995          16.2    82   \n",
       "386  25.0          6         181.0       110.0    2945          16.4    82   \n",
       "390  32.0          4         144.0        96.0    2665          13.9    82   \n",
       "392  27.0          4         151.0        90.0    2950          17.3    82   \n",
       "\n",
       "     origin                   name  \n",
       "2         1      buick skylark 320  \n",
       "3         1     plymouth satellite  \n",
       "4         1          amc rebel sst  \n",
       "5         1            ford torino  \n",
       "6         1       ford galaxie 500  \n",
       "..      ...                    ...  \n",
       "384       3     honda civic (auto)  \n",
       "385       3          datsun 310 gx  \n",
       "386       1  buick century limited  \n",
       "390       3       toyota celica gt  \n",
       "392       1       chevrolet camaro  \n",
       "\n",
       "[196 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_df[auto_test_maks_no_gaps]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb6f46-087a-4301-8761-965078f5430e",
   "metadata": {},
   "source": [
    "Complete: test indices return the same rows in R and Python using boolean index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9441963-1c05-45f6-b57e-299ba605f35e",
   "metadata": {},
   "source": [
    "### Checking that MSE of testing data matches in R and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2e58fa4-7cb4-4f9c-a231-6c3e086c89db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 23.26601\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "attach(Auto)\n",
    "mean((mpg - predict(lm.fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3862df21-81cb-4f36-ae60-d55e6989ac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.2660086465003"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lm_fit.predict(auto_df.iloc[test_idx]['horsepower'])\n",
    "((auto_df.iloc[test_idx]['mpg'] - pred)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03f546-88db-45c4-8235-5c5f319ad57a",
   "metadata": {},
   "source": [
    "Complete: MSE matches in R and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b62bd-7c93-4a9e-9523-bb4a3d1246a5",
   "metadata": {},
   "source": [
    "### Polynomial Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "257de8b6-31c7-4b92-8b1c-8466e92a55ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 18.71646\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
    "mean((mpg - predict(lm.fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ed33e-c6f7-4ab8-bcfb-c16a0feffa3e",
   "metadata": {},
   "source": [
    "#### 2nd Degree Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e9916-42b5-4274-8dc8-629cfda81f89",
   "metadata": {},
   "source": [
    "##### Trying to using ortho_poly_fit with smf.ols in order to mimic R's lm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b164383-7df9-45af-bff0-1c0a3f6daba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## http://davmre.github.io/blog/python/2013/12/15/orthogonal_poly\n",
    "\n",
    "def ortho_poly_fit(x, degree = 1):\n",
    "    n = degree + 1\n",
    "    x = np.asarray(x).flatten()\n",
    "    if(degree >= len(np.unique(x))):\n",
    "            stop(\"'degree' must be less than number of unique points\")\n",
    "    xbar = np.mean(x)\n",
    "    x = x - xbar\n",
    "    X = np.fliplr(np.vander(x, n))\n",
    "    q,r = np.linalg.qr(X)\n",
    "\n",
    "    z = np.diag(np.diag(r))\n",
    "    raw = np.dot(q, z)\n",
    "\n",
    "    norm2 = np.sum(raw**2, axis=0)\n",
    "    alpha = (np.sum((raw**2)*np.reshape(x,(-1,1)), axis=0)/norm2 + xbar)[:degree]\n",
    "    Z = raw / np.sqrt(norm2)\n",
    "    return Z[:,1:], norm2, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd44ccb-dc44-427f-bd06-11c490f092f5",
   "metadata": {},
   "source": [
    "##### Checking that ortho_poly_fit in Python produces same output as poly in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec69994e-5821-46f2-8171-db45c3561807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  1             2\n",
      "  [1,]  0.052013624 -0.0702694928\n",
      "  [2,]  0.232433458  0.3472748050\n",
      "  [3,]  0.089996747 -0.0423605989\n",
      "  [4,]  0.232433458  0.3472748050\n",
      "  [5,] -0.014456842 -0.0421162572\n",
      "  [6,] -0.014456842 -0.0421162572\n",
      "  [7,] -0.010658529 -0.0463648010\n",
      "  [8,] -0.027750935 -0.0247265570\n",
      "  [9,] -0.107515493  0.1619250158\n",
      " [10,] -0.023952622 -0.0300950106\n",
      " [11,]  0.019727969 -0.0688340785\n",
      " [12,] -0.023952622 -0.0300950106\n",
      " [13,]  0.171660461  0.1259947978\n",
      " [14,] -0.027750935 -0.0247265570\n",
      " [15,] -0.023952622 -0.0300950106\n",
      " [16,] -0.004961061 -0.0521376649\n",
      " [17,] -0.027750935 -0.0247265570\n",
      " [18,] -0.004961061 -0.0521376649\n",
      " [19,]  0.137475650  0.0375218951\n",
      " [20,]  0.095694215 -0.0354144871\n",
      " [21,]  0.089996747 -0.0423605989\n",
      " [22,]  0.146971431  0.0594979107\n",
      " [23,]  0.127979870  0.0175457183\n",
      " [24,]  0.137475650  0.0375218951\n",
      " [25,]  0.014030501 -0.0661809634\n",
      " [26,] -0.027750935 -0.0247265570\n",
      " [27,] -0.031549247 -0.0190381292\n",
      " [28,] -0.023952622 -0.0300950106\n",
      " [29,] -0.061935745  0.0379883656\n",
      " [30,] -0.071431526  0.0600088070\n",
      " [31,] -0.031549247 -0.0190381292\n",
      " [32,]  0.089996747 -0.0423605989\n",
      " [33,]  0.095694215 -0.0354144871\n",
      " [34,]  0.165962993  0.1094494590\n",
      " [35,]  0.089996747 -0.0423605989\n",
      " [36,]  0.089996747 -0.0423605989\n",
      " [37,] -0.050540809  0.0142036233\n",
      " [38,] -0.029650091 -0.0219223399\n",
      " [39,] -0.063834902  0.0422324668\n",
      " [40,] -0.031549247 -0.0190381292\n",
      " [41,] -0.027750935 -0.0247265570\n",
      " [42,]  0.137475650  0.0375218951\n",
      " [43,]  0.089996747 -0.0423605989\n",
      " [44,]  0.065307717 -0.0641410869\n",
      " [45,]  0.089996747 -0.0423605989\n",
      " [46,]  0.105189996 -0.0222377628\n",
      " [47,]  0.089996747 -0.0423605989\n",
      " [48,] -0.004961061 -0.0521376649\n",
      " [49,] -0.107515493  0.1619250158\n",
      " [50,]  0.089996747 -0.0423605989\n",
      " [51,]  0.122282401  0.0065199350\n",
      " [52,]  0.127979870  0.0175457183\n",
      " [53,]  0.146971431  0.0594979107\n",
      " [54,] -0.004961061 -0.0521376649\n",
      " [55,] -0.027750935 -0.0247265570\n",
      " [56,] -0.016355998 -0.0398719950\n",
      " [57,] -0.023952622 -0.0300950106\n",
      " [58,]  0.241929239  0.3892492103\n",
      " [59,] -0.101818025  0.1439131375\n",
      " [60,] -0.052439965  0.0179677631\n",
      " [61,]  0.089996747 -0.0423605989\n",
      " [62,]  0.014030501 -0.0661809634\n",
      " [63,]  0.146971431  0.0594979107\n",
      " [64,] -0.004961061 -0.0521376649\n",
      " [65,] -0.004961061 -0.0521376649\n",
      " [66,] -0.042944184 -0.0000530004\n",
      " [67,] -0.071431526  0.0600088070\n",
      " [68,]  0.014030501 -0.0661809634\n",
      " [69,]  0.071005185 -0.0603147238\n",
      " [70,]  0.071005185 -0.0603147238\n",
      " [71,] -0.037246716 -0.0099055358\n",
      " [72,] -0.067633214  0.0509606498\n",
      " [73,] -0.096120556  0.1266212011\n",
      " [74,] -0.052439965  0.0179677631\n",
      " [75,] -0.018255154 -0.0375477392\n",
      " [76,]  0.004534720 -0.0601592336\n",
      " [77,]  0.089996747 -0.0423605989\n",
      " [78,]  0.014030501 -0.0661809634\n",
      " [79,]  0.004534720 -0.0601592336\n",
      " [80,]  0.014030501 -0.0661809634\n",
      " [81,]  0.014030501 -0.0661809634\n",
      " [82,]  0.050114467 -0.0708250052\n",
      " [83,] -0.037246716 -0.0099055358\n",
      " [84,] -0.012557686 -0.0442805259\n",
      " [85,] -0.010658529 -0.0463648010\n",
      " [86,] -0.061935745  0.0379883656\n",
      " [87,] -0.014456842 -0.0421162572\n",
      " [88,] -0.031549247 -0.0190381292\n",
      " [89,] -0.037246716 -0.0099055358\n",
      " [90,]  0.089996747 -0.0423605989\n",
      " [91,] -0.023952622 -0.0300950106\n",
      " [92,] -0.096120556  0.1266212011\n",
      " [93,] -0.080927307  0.0840290874\n",
      " [94,] -0.004961061 -0.0521376649\n",
      " [95,] -0.014456842 -0.0421162572\n",
      " [96,] -0.052439965  0.0179677631\n",
      " [97,] -0.001162749 -0.0555862731\n",
      " [98,]  0.089996747 -0.0423605989\n",
      " [99,]  0.080500966 -0.0523375808\n",
      "[100,]  0.052013624 -0.0702694928\n",
      "[101,]  0.089996747 -0.0423605989\n",
      "[102,] -0.084725619  0.0941971545\n",
      "[103,] -0.012557686 -0.0442805259\n",
      "[104,] -0.061935745  0.0379883656\n",
      "[105,]  0.080500966 -0.0523375808\n",
      "[106,]  0.014030501 -0.0661809634\n",
      "[107,]  0.052013624 -0.0702694928\n",
      "[108,]  0.014030501 -0.0661809634\n",
      "[109,]  0.004534720 -0.0601592336\n",
      "[110,]  0.146971431  0.0594979107\n",
      "[111,]  0.127979870  0.0175457183\n",
      "[112,]  0.165962993  0.1094494590\n",
      "[113,] -0.027750935 -0.0247265570\n",
      "[114,] -0.052439965  0.0179677631\n",
      "[115,] -0.037246716 -0.0099055358\n",
      "[116,] -0.067633214  0.0509606498\n",
      "[117,] -0.046742496  0.0069153243\n",
      "[118,] -0.010658529 -0.0463648010\n",
      "[119,]  0.014030501 -0.0661809634\n",
      "[120,] -0.069532370  0.0554447316\n",
      "[121,] -0.061935745  0.0379883656\n",
      "[122,] -0.080927307  0.0840290874\n",
      "[123,]  0.014030501 -0.0661809634\n",
      "[124,] -0.014456842 -0.0421162572\n",
      "[125,] -0.004961061 -0.0521376649\n",
      "[126,] -0.033448403 -0.0160739250\n",
      "[127,]  0.069106029 -0.0616701717\n",
      "[128,]  0.004534720 -0.0601592336\n",
      "[129,] -0.033448403 -0.0160739250\n",
      "[130,] -0.010658529 -0.0463648010\n",
      "[131,] -0.060036589  0.0338242580\n",
      "[132,]  0.023526281 -0.0702028542\n",
      "[133,] -0.033448403 -0.0160739250\n",
      "[134,] -0.027750935 -0.0247265570\n",
      "[135,] -0.023952622 -0.0300950106\n",
      "[136,]  0.052013624 -0.0702694928\n",
      "[137,]  0.050114467 -0.0708250052\n",
      "[138,]  0.061509404 -0.0662920278\n",
      "[139,]  0.074803497 -0.0573638473\n",
      "[140,]  0.042517843 -0.0722471189\n",
      "[141,] -0.042944184 -0.0000530004\n",
      "[142,] -0.042944184 -0.0000530004\n",
      "[143,] -0.048641652  0.0105194770\n",
      "[144,] -0.060036589  0.0338242580\n",
      "[145,] -0.023952622 -0.0300950106\n",
      "[146,] -0.023952622 -0.0300950106\n",
      "[147,]  0.023526281 -0.0702028542\n",
      "[148,] -0.023952622 -0.0300950106\n",
      "[149,] -0.080927307  0.0840290874\n",
      "[150,] -0.061935745  0.0379883656\n",
      "[151,] -0.027750935 -0.0247265570\n",
      "[152,] -0.023952622 -0.0300950106\n",
      "[153,] -0.052439965  0.0179677631\n",
      "[154,] -0.020154310 -0.0351434899\n",
      "[155,] -0.071431526  0.0600088070\n",
      "[156,] -0.103717181  0.1498371034\n",
      "[157,] -0.103717181  0.1498371034\n",
      "[158,] -0.067633214  0.0509606498\n",
      "[159,] -0.067633214  0.0509606498\n",
      "[160,] -0.067633214  0.0509606498\n",
      "[161,] -0.077128995  0.0741809946\n",
      "[162,]  0.055811936 -0.0689184875\n",
      "[163,] -0.020154310 -0.0351434899\n",
      "[164,] -0.084725619  0.0941971545\n",
      "[165,] -0.073330682  0.0646528760\n",
      "[166,] -0.080927307  0.0840290874\n",
      "[167,] -0.067633214  0.0509606498\n",
      "[168,] -0.071431526  0.0600088070\n",
      "[169,] -0.075229839  0.0693769385\n",
      "[170,] -0.071431526  0.0600088070\n",
      "[171,] -0.071431526  0.0600088070\n",
      "[172,] -0.054339121  0.0218118965\n",
      "[173,] -0.042944184 -0.0000530004\n",
      "[174,]  0.033022062 -0.0722249060\n",
      "[175,] -0.033448403 -0.0160739250\n",
      "[176,] -0.027750935 -0.0247265570\n",
      "[177,] -0.027750935 -0.0247265570\n",
      "[178,] -0.033448403 -0.0160739250\n",
      "[179,] -0.035347559 -0.0130297272\n",
      "[180,] -0.023952622 -0.0300950106\n",
      "[181,] -0.020154310 -0.0351434899\n",
      "[182,] -0.065734058  0.0465565615\n",
      "[183,] -0.075229839  0.0693769385\n",
      "[184,] -0.061935745  0.0379883656\n",
      "[185,] -0.027750935 -0.0247265570\n",
      "[186,] -0.052439965  0.0179677631\n",
      "[187,] -0.067633214  0.0509606498\n",
      "[188,] -0.033448403 -0.0160739250\n",
      "[189,] -0.020154310 -0.0351434899\n",
      "[190,]  0.017828813 -0.0680297004\n",
      "[191,] -0.035347559 -0.0130297272\n",
      "[192,] -0.031549247 -0.0190381292\n",
      "[193,] -0.096120556  0.1266212011\n",
      "[194,] -0.035347559 -0.0130297272\n",
      "[195,] -0.044843340  0.0033911652\n",
      "[196,] -0.039145872 -0.0067013509\n",
      "attr(,\"coefs\")\n",
      "attr(,\"coefs\")$alpha\n",
      "[1] 102.6122 142.4988\n",
      "\n",
      "attr(,\"coefs\")$norm2\n",
      "[1]         1.0       196.0    277254.5 625100662.2\n",
      "\n",
      "attr(,\"degree\")\n",
      "[1] 1 2\n",
      "attr(,\"class\")\n",
      "[1] \"poly\"   \"matrix\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "poly(horsepower[sort(train)], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c972bece-fbca-47b3-8c30-dd80ceeee7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.20136235e-02, -7.02694928e-02],\n",
       "       [ 2.32433458e-01,  3.47274805e-01],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 2.32433458e-01,  3.47274805e-01],\n",
       "       [-1.44568417e-02, -4.21162572e-02],\n",
       "       [-1.44568417e-02, -4.21162572e-02],\n",
       "       [-1.06585294e-02, -4.63648010e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-1.07515493e-01,  1.61925016e-01],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [ 1.97279690e-02, -6.88340785e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [ 1.71660461e-01,  1.25994798e-01],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [-4.96106096e-03, -5.21376649e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-4.96106096e-03, -5.21376649e-02],\n",
       "       [ 1.37475650e-01,  3.75218951e-02],\n",
       "       [ 9.56942150e-02, -3.54144871e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 1.46971431e-01,  5.94979107e-02],\n",
       "       [ 1.27979870e-01,  1.75457183e-02],\n",
       "       [ 1.37475650e-01,  3.75218951e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-3.15492471e-02, -1.90381292e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [-6.19357455e-02,  3.79883656e-02],\n",
       "       [-7.14315262e-02,  6.00088070e-02],\n",
       "       [-3.15492471e-02, -1.90381292e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 9.56942150e-02, -3.54144871e-02],\n",
       "       [ 1.65962993e-01,  1.09449459e-01],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [-5.05408086e-02,  1.42036233e-02],\n",
       "       [-2.96500909e-02, -2.19223399e-02],\n",
       "       [-6.38349016e-02,  4.22324668e-02],\n",
       "       [-3.15492471e-02, -1.90381292e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [ 1.37475650e-01,  3.75218951e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 6.53077166e-02, -6.41410869e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 1.05189996e-01, -2.22377628e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [-4.96106096e-03, -5.21376649e-02],\n",
       "       [-1.07515493e-01,  1.61925016e-01],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 1.22282401e-01,  6.51993502e-03],\n",
       "       [ 1.27979870e-01,  1.75457183e-02],\n",
       "       [ 1.46971431e-01,  5.94979107e-02],\n",
       "       [-4.96106096e-03, -5.21376649e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-1.63559979e-02, -3.98719950e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [ 2.41929239e-01,  3.89249210e-01],\n",
       "       [-1.01818025e-01,  1.43913137e-01],\n",
       "       [-5.24399647e-02,  1.79677631e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [ 1.46971431e-01,  5.94979107e-02],\n",
       "       [-4.96106096e-03, -5.21376649e-02],\n",
       "       [-4.96106096e-03, -5.21376649e-02],\n",
       "       [-4.29441840e-02, -5.30004006e-05],\n",
       "       [-7.14315262e-02,  6.00088070e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [ 7.10051850e-02, -6.03147238e-02],\n",
       "       [ 7.10051850e-02, -6.03147238e-02],\n",
       "       [-3.72467155e-02, -9.90553581e-03],\n",
       "       [-6.76332139e-02,  5.09606498e-02],\n",
       "       [-9.61205562e-02,  1.26621201e-01],\n",
       "       [-5.24399647e-02,  1.79677631e-02],\n",
       "       [-1.82551540e-02, -3.75477392e-02],\n",
       "       [ 4.53471979e-03, -6.01592336e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [ 4.53471979e-03, -6.01592336e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [ 5.01144674e-02, -7.08250052e-02],\n",
       "       [-3.72467155e-02, -9.90553581e-03],\n",
       "       [-1.25576856e-02, -4.42805259e-02],\n",
       "       [-1.06585294e-02, -4.63648010e-02],\n",
       "       [-6.19357455e-02,  3.79883656e-02],\n",
       "       [-1.44568417e-02, -4.21162572e-02],\n",
       "       [-3.15492471e-02, -1.90381292e-02],\n",
       "       [-3.72467155e-02, -9.90553581e-03],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [-9.61205562e-02,  1.26621201e-01],\n",
       "       [-8.09273070e-02,  8.40290874e-02],\n",
       "       [-4.96106096e-03, -5.21376649e-02],\n",
       "       [-1.44568417e-02, -4.21162572e-02],\n",
       "       [-5.24399647e-02,  1.79677631e-02],\n",
       "       [-1.16274866e-03, -5.55862731e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [ 8.05009658e-02, -5.23375808e-02],\n",
       "       [ 5.20136235e-02, -7.02694928e-02],\n",
       "       [ 8.99967465e-02, -4.23605989e-02],\n",
       "       [-8.47256193e-02,  9.41971545e-02],\n",
       "       [-1.25576856e-02, -4.42805259e-02],\n",
       "       [-6.19357455e-02,  3.79883656e-02],\n",
       "       [ 8.05009658e-02, -5.23375808e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [ 5.20136235e-02, -7.02694928e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [ 4.53471979e-03, -6.01592336e-02],\n",
       "       [ 1.46971431e-01,  5.94979107e-02],\n",
       "       [ 1.27979870e-01,  1.75457183e-02],\n",
       "       [ 1.65962993e-01,  1.09449459e-01],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-5.24399647e-02,  1.79677631e-02],\n",
       "       [-3.72467155e-02, -9.90553581e-03],\n",
       "       [-6.76332139e-02,  5.09606498e-02],\n",
       "       [-4.67424963e-02,  6.91532433e-03],\n",
       "       [-1.06585294e-02, -4.63648010e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [-6.95323701e-02,  5.54447316e-02],\n",
       "       [-6.19357455e-02,  3.79883656e-02],\n",
       "       [-8.09273070e-02,  8.40290874e-02],\n",
       "       [ 1.40305005e-02, -6.61809634e-02],\n",
       "       [-1.44568417e-02, -4.21162572e-02],\n",
       "       [-4.96106096e-03, -5.21376649e-02],\n",
       "       [-3.34484032e-02, -1.60739250e-02],\n",
       "       [ 6.91060289e-02, -6.16701717e-02],\n",
       "       [ 4.53471979e-03, -6.01592336e-02],\n",
       "       [-3.34484032e-02, -1.60739250e-02],\n",
       "       [-1.06585294e-02, -4.63648010e-02],\n",
       "       [-6.00365893e-02,  3.38242580e-02],\n",
       "       [ 2.35262813e-02, -7.02028542e-02],\n",
       "       [-3.34484032e-02, -1.60739250e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [ 5.20136235e-02, -7.02694928e-02],\n",
       "       [ 5.01144674e-02, -7.08250052e-02],\n",
       "       [ 6.15094043e-02, -6.62920278e-02],\n",
       "       [ 7.48034973e-02, -5.73638473e-02],\n",
       "       [ 4.25178428e-02, -7.22471189e-02],\n",
       "       [-4.29441840e-02, -5.30004006e-05],\n",
       "       [-4.29441840e-02, -5.30004006e-05],\n",
       "       [-4.86416524e-02,  1.05194770e-02],\n",
       "       [-6.00365893e-02,  3.38242580e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [ 2.35262813e-02, -7.02028542e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [-8.09273070e-02,  8.40290874e-02],\n",
       "       [-6.19357455e-02,  3.79883656e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [-5.24399647e-02,  1.79677631e-02],\n",
       "       [-2.01543102e-02, -3.51434899e-02],\n",
       "       [-7.14315262e-02,  6.00088070e-02],\n",
       "       [-1.03717181e-01,  1.49837103e-01],\n",
       "       [-1.03717181e-01,  1.49837103e-01],\n",
       "       [-6.76332139e-02,  5.09606498e-02],\n",
       "       [-6.76332139e-02,  5.09606498e-02],\n",
       "       [-6.76332139e-02,  5.09606498e-02],\n",
       "       [-7.71289947e-02,  7.41809946e-02],\n",
       "       [ 5.58119358e-02, -6.89184875e-02],\n",
       "       [-2.01543102e-02, -3.51434899e-02],\n",
       "       [-8.47256193e-02,  9.41971545e-02],\n",
       "       [-7.33306824e-02,  6.46528760e-02],\n",
       "       [-8.09273070e-02,  8.40290874e-02],\n",
       "       [-6.76332139e-02,  5.09606498e-02],\n",
       "       [-7.14315262e-02,  6.00088070e-02],\n",
       "       [-7.52298385e-02,  6.93769385e-02],\n",
       "       [-7.14315262e-02,  6.00088070e-02],\n",
       "       [-7.14315262e-02,  6.00088070e-02],\n",
       "       [-5.43391209e-02,  2.18118965e-02],\n",
       "       [-4.29441840e-02, -5.30004006e-05],\n",
       "       [ 3.30220620e-02, -7.22249060e-02],\n",
       "       [-3.34484032e-02, -1.60739250e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-3.34484032e-02, -1.60739250e-02],\n",
       "       [-3.53475594e-02, -1.30297272e-02],\n",
       "       [-2.39526225e-02, -3.00950106e-02],\n",
       "       [-2.01543102e-02, -3.51434899e-02],\n",
       "       [-6.57340578e-02,  4.65565615e-02],\n",
       "       [-7.52298385e-02,  6.93769385e-02],\n",
       "       [-6.19357455e-02,  3.79883656e-02],\n",
       "       [-2.77509348e-02, -2.47265570e-02],\n",
       "       [-5.24399647e-02,  1.79677631e-02],\n",
       "       [-6.76332139e-02,  5.09606498e-02],\n",
       "       [-3.34484032e-02, -1.60739250e-02],\n",
       "       [-2.01543102e-02, -3.51434899e-02],\n",
       "       [ 1.78288128e-02, -6.80297004e-02],\n",
       "       [-3.53475594e-02, -1.30297272e-02],\n",
       "       [-3.15492471e-02, -1.90381292e-02],\n",
       "       [-9.61205562e-02,  1.26621201e-01],\n",
       "       [-3.53475594e-02, -1.30297272e-02],\n",
       "       [-4.48433401e-02,  3.39116519e-03],\n",
       "       [-3.91458717e-02, -6.70135090e-03]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ortho_poly_fit(auto_df.iloc[train_idx-1]['horsepower'], 2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23fd970-a201-4b87-8385-e25ff927e662",
   "metadata": {},
   "source": [
    "Complete: ortho_poly_fit in Python and poly in R produce same output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e47c8-a67e-42d8-bdf9-82dbd43a0b15",
   "metadata": {},
   "source": [
    "##### Checking that using poly and lm in R produce same model as using ortho_poly_fit and smf.ols in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3426a53c-9409-46a8-a27d-290bfb50a330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
      "\n",
      "Residuals:\n",
      "     Min       1Q   Median       3Q      Max \n",
      "-12.8711  -2.6655  -0.0096   2.0806  16.1063 \n",
      "\n",
      "Coefficients:\n",
      "                      Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)            23.5496     0.3175  74.182  < 2e-16 ***\n",
      "poly(horsepower, 2)1 -123.5881     6.4587 -19.135  < 2e-16 ***\n",
      "poly(horsepower, 2)2   47.7189     6.3613   7.501 2.25e-12 ***\n",
      "---\n",
      "Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n",
      "\n",
      "Residual standard error: 4.439 on 193 degrees of freedom\n",
      "Multiple R-squared:  0.705,\tAdjusted R-squared:  0.702 \n",
      "F-statistic: 230.6 on 2 and 193 DF,  p-value: < 2.2e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary(lm.fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d19ca82a-ee1f-4576-be92-7d40330ba01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model2_ortho_poly  = smf.ols(formula = 'mpg ~ ortho_poly_fit(horsepower, 2)[0]', data = auto_df.iloc[train_idx-1])\n",
    "lm_fit2_ortho_poly = lm_model2_ortho_poly.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c6fab60-4ce7-406d-b8aa-8c833bec9b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   230.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>6.83e-52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:40:34</td>     <th>  Log-Likelihood:    </th> <td> -568.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1143.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   193</td>      <th>  BIC:               </th> <td>   1153.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                           <td>   23.8745</td> <td>    0.317</td> <td>   75.298</td> <td> 0.000</td> <td>   23.249</td> <td>   24.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ortho_poly_fit(horsepower, 2)[0][0]</th> <td>  -89.3337</td> <td>    4.439</td> <td>  -20.125</td> <td> 0.000</td> <td>  -98.089</td> <td>  -80.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ortho_poly_fit(horsepower, 2)[0][1]</th> <td>   33.2985</td> <td>    4.439</td> <td>    7.501</td> <td> 0.000</td> <td>   24.543</td> <td>   42.054</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.485</td> <th>  Durbin-Watson:     </th> <td>   1.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  16.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.354</td> <th>  Prob(JB):          </th> <td>0.000204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.257</td> <th>  Cond. No.          </th> <td>    14.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.705\n",
       "Model:                            OLS   Adj. R-squared:                  0.702\n",
       "Method:                 Least Squares   F-statistic:                     230.6\n",
       "Date:                Sat, 21 Jan 2023   Prob (F-statistic):           6.83e-52\n",
       "Time:                        18:40:34   Log-Likelihood:                -568.72\n",
       "No. Observations:                 196   AIC:                             1143.\n",
       "Df Residuals:                     193   BIC:                             1153.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================================\n",
       "                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------\n",
       "Intercept                              23.8745      0.317     75.298      0.000      23.249      24.500\n",
       "ortho_poly_fit(horsepower, 2)[0][0]   -89.3337      4.439    -20.125      0.000     -98.089     -80.579\n",
       "ortho_poly_fit(horsepower, 2)[0][1]    33.2985      4.439      7.501      0.000      24.543      42.054\n",
       "==============================================================================\n",
       "Omnibus:                       11.485   Durbin-Watson:                   1.232\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               16.996\n",
       "Skew:                           0.354   Prob(JB):                     0.000204\n",
       "Kurtosis:                       4.257   Cond. No.                         14.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit2_ortho_poly.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0036bd-ebe0-4017-8a7a-68a4d7a7a65a",
   "metadata": {},
   "source": [
    "**Incomplete: poly and lm in R produce a different model than ortho_poly_fit and smf.ols in Python.  As far as I can tell, the input to both functions is the same and am not sure why the outputs are different.  Perhaps I need to read the source code and try to understand how lm works compared to smf.ols in order to see how the inputs are used.  Since the inputs are the same, as far as I can tell, my best guess is that the outputs are different because lm and smf.ols work in different ways.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fca6b1-7f9d-4b89-9bf0-784d098f6b18",
   "metadata": {},
   "source": [
    "##### Checking if using poly and lm in R produce same model as PolynomialFeatures with smf.ols in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7aa9ba0-2f93-4f75-9ec1-9ec74e5df03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
      "\n",
      "Residuals:\n",
      "     Min       1Q   Median       3Q      Max \n",
      "-12.8711  -2.6655  -0.0096   2.0806  16.1063 \n",
      "\n",
      "Coefficients:\n",
      "                      Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)            23.5496     0.3175  74.182  < 2e-16 ***\n",
      "poly(horsepower, 2)1 -123.5881     6.4587 -19.135  < 2e-16 ***\n",
      "poly(horsepower, 2)2   47.7189     6.3613   7.501 2.25e-12 ***\n",
      "---\n",
      "Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n",
      "\n",
      "Residual standard error: 4.439 on 193 degrees of freedom\n",
      "Multiple R-squared:  0.705,\tAdjusted R-squared:  0.702 \n",
      "F-statistic: 230.6 on 2 and 193 DF,  p-value: < 2.2e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary(lm.fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c388c5b4-55c1-4bcb-abe9-9040876598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(2, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b415b9e3-d423-44ee-9ec4-029c63009772",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model2_poly_feats  = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(horsepower).reshape(-1,1))', data = auto_df_no_gaps, subset=train_idx)\n",
    "lm_fit2_poly_feats = lm_model2_poly_feats.fit(method='qr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a2ed668-9193-42aa-bb5a-deef8ede93ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   230.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>6.83e-52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:40:40</td>     <th>  Log-Likelihood:    </th> <td> -568.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1143.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   193</td>      <th>  BIC:               </th> <td>   1153.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                      <td></td>                                         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                                 <td>   58.8738</td> <td>    2.519</td> <td>   23.368</td> <td> 0.000</td> <td>   53.905</td> <td>   63.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[0]</th> <td>   -0.4961</td> <td>    0.044</td> <td>  -11.192</td> <td> 0.000</td> <td>   -0.584</td> <td>   -0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[1]</th> <td>    0.0013</td> <td>    0.000</td> <td>    7.501</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.485</td> <th>  Durbin-Watson:     </th> <td>   1.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  16.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.354</td> <th>  Prob(JB):          </th> <td>0.000204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.257</td> <th>  Cond. No.          </th> <td>1.21e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.21e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.705\n",
       "Model:                            OLS   Adj. R-squared:                  0.702\n",
       "Method:                 Least Squares   F-statistic:                     230.6\n",
       "Date:                Sat, 21 Jan 2023   Prob (F-statistic):           6.83e-52\n",
       "Time:                        18:40:40   Log-Likelihood:                -568.72\n",
       "No. Observations:                 196   AIC:                             1143.\n",
       "Df Residuals:                     193   BIC:                             1153.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================================================================\n",
       "                                                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                    58.8738      2.519     23.368      0.000      53.905      63.843\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[0]    -0.4961      0.044    -11.192      0.000      -0.584      -0.409\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[1]     0.0013      0.000      7.501      0.000       0.001       0.002\n",
       "==============================================================================\n",
       "Omnibus:                       11.485   Durbin-Watson:                   1.232\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               16.996\n",
       "Skew:                           0.354   Prob(JB):                     0.000204\n",
       "Kurtosis:                       4.257   Cond. No.                     1.21e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.21e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit2_poly_feats.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b2f20-7d01-4c43-a103-3750f1aa17fe",
   "metadata": {},
   "source": [
    "**Incomplete: Using PolynomialFeatures with smf.ols doesn't produce the same model as poly and lm in R.  Although the models look different, that's because PolynomialFeatures returns an array where the vectors aren't orthogonalized, whereas poly in R does.  When the array isn't orthogonalized, the inputs are much larger and affect the coefficients for the model, hence the difference.**\n",
    "\n",
    "**If I generate the model in R using poly(horsepower, 2, raw=TRUE), then poly doesn't return and orthogonalized array and the coefficients of the model in R and Python match.  If I was able to orthogonalize the array from PolynomialFeatures in Pythonm, then I think the models would generate the same coefficients.  I may look into this later, but it's a little unncessary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7bc76-4bdc-41fb-b7ef-fa195dff9cc2",
   "metadata": {},
   "source": [
    "##### Checking MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c359913-1f22-441e-a8b6-40d143a55d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 18.71646\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "mean((mpg - predict(lm.fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90355c4-f3ce-42d9-99ef-80548193f4b5",
   "metadata": {},
   "source": [
    "###### Checking MSEs using ortho_poly_fit and smf.ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63649e14-d5be-4a3d-8cc6-e1123c753faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.665806429149843"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2_ortho_poly = lm_fit2_ortho_poly.predict(auto_df_no_gaps[auto_test_maks_no_gaps]['horsepower'])\n",
    "\n",
    "((pred2_ortho_poly - auto_df_no_gaps[auto_test_maks_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f5abe-bd02-4743-9765-b173dbefae33",
   "metadata": {},
   "source": [
    "###### Checking MSEs using PolynomialFeatures and smf.ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f9b0a90-6858-44b5-9ecc-25e71716da6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.71645949338283"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2_poly_feats = lm_fit2_poly_feats.predict(auto_df_no_gaps[auto_test_maks_no_gaps]['horsepower'])\n",
    "\n",
    "((pred2_poly_feats - auto_df_no_gaps[auto_test_maks_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d3f4a-36a0-4d1b-aa9f-bce3d04d4744",
   "metadata": {},
   "source": [
    "**Complete: The MSE from using PolynomialFeatures with smf.ols matches in Python and R, despite the models between Python and R not entirely matching, due to the difference in inputs where poly returns orthogonalized vectors while PolynomialFeatures doesn't**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261f570-e274-4127-9a22-4e645e31068a",
   "metadata": {},
   "source": [
    "#### 3rd Degree Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877ffad-b4bc-4add-8dcd-2eb940cb9d58",
   "metadata": {},
   "source": [
    "##### Checking that ortho_poly_fit and smf.ols produce same model as poly and lm in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89b0d568-f81a-4aa3-9ae0-58b531f5a33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = mpg ~ poly(horsepower, 3), data = Auto, subset = train)\n",
      "\n",
      "Residuals:\n",
      "     Min       1Q   Median       3Q      Max \n",
      "-12.6625  -2.7108   0.0805   2.0724  16.1378 \n",
      "\n",
      "Coefficients:\n",
      "                      Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)            23.5527     0.3185  73.946  < 2e-16 ***\n",
      "poly(horsepower, 3)1 -123.6143     6.4755 -19.089  < 2e-16 ***\n",
      "poly(horsepower, 3)2   47.8284     6.3935   7.481 2.58e-12 ***\n",
      "poly(horsepower, 3)3    1.3825     5.8107   0.238    0.812    \n",
      "---\n",
      "Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n",
      "\n",
      "Residual standard error: 4.45 on 192 degrees of freedom\n",
      "Multiple R-squared:  0.7051,\tAdjusted R-squared:  0.7005 \n",
      "F-statistic:   153 on 3 and 192 DF,  p-value: < 2.2e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)\n",
    "summary(lm.fit3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc64ba77-b015-412e-87fb-5934dc1f5bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   153.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>1.14e-50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:04</td>     <th>  Log-Likelihood:    </th> <td> -568.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1145.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   192</td>      <th>  BIC:               </th> <td>   1158.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                           <td>   23.8745</td> <td>    0.318</td> <td>   75.114</td> <td> 0.000</td> <td>   23.248</td> <td>   24.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ortho_poly_fit(horsepower, 3)[0][0]</th> <td>  -89.3337</td> <td>    4.450</td> <td>  -20.076</td> <td> 0.000</td> <td>  -98.111</td> <td>  -80.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ortho_poly_fit(horsepower, 3)[0][1]</th> <td>   33.2985</td> <td>    4.450</td> <td>    7.483</td> <td> 0.000</td> <td>   24.522</td> <td>   42.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ortho_poly_fit(horsepower, 3)[0][2]</th> <td>    1.0587</td> <td>    4.450</td> <td>    0.238</td> <td> 0.812</td> <td>   -7.718</td> <td>    9.836</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.392</td> <th>  Durbin-Watson:     </th> <td>   1.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  16.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.365</td> <th>  Prob(JB):          </th> <td>0.000287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.211</td> <th>  Cond. No.          </th> <td>    14.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.705\n",
       "Model:                            OLS   Adj. R-squared:                  0.701\n",
       "Method:                 Least Squares   F-statistic:                     153.0\n",
       "Date:                Sat, 21 Jan 2023   Prob (F-statistic):           1.14e-50\n",
       "Time:                        18:57:04   Log-Likelihood:                -568.69\n",
       "No. Observations:                 196   AIC:                             1145.\n",
       "Df Residuals:                     192   BIC:                             1158.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================================\n",
       "                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------\n",
       "Intercept                              23.8745      0.318     75.114      0.000      23.248      24.501\n",
       "ortho_poly_fit(horsepower, 3)[0][0]   -89.3337      4.450    -20.076      0.000     -98.111     -80.557\n",
       "ortho_poly_fit(horsepower, 3)[0][1]    33.2985      4.450      7.483      0.000      24.522      42.075\n",
       "ortho_poly_fit(horsepower, 3)[0][2]     1.0587      4.450      0.238      0.812      -7.718       9.836\n",
       "==============================================================================\n",
       "Omnibus:                       11.392   Durbin-Watson:                   1.228\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               16.312\n",
       "Skew:                           0.365   Prob(JB):                     0.000287\n",
       "Kurtosis:                       4.211   Cond. No.                         14.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_model3_ortho_poly = smf.ols(formula='mpg ~ ortho_poly_fit(horsepower, 3)[0]', data=auto_df_no_gaps, subset=train_idx)\n",
    "\n",
    "lm_fit3_ortho_poly = lm_model3_ortho_poly.fit()\n",
    "\n",
    "lm_fit3_ortho_poly.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe4258-9723-4980-a3ae-b1c1599bbd15",
   "metadata": {},
   "source": [
    "**Incomplete: The models are not the same**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1587ec-0bef-4c17-a664-7d8edfb8b055",
   "metadata": {},
   "source": [
    "##### Checking that PolynomialFeatures and smf.ols produce same model as poly and lm in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "159eaa7d-ddf0-451f-b937-8ede7748e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   153.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>1.14e-50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:02:49</td>     <th>  Log-Likelihood:    </th> <td> -568.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1145.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   192</td>      <th>  BIC:               </th> <td>   1158.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                      <td></td>                                         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                                 <td>   57.5977</td> <td>    5.928</td> <td>    9.715</td> <td> 0.000</td> <td>   45.904</td> <td>   69.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[0]</th> <td>   -0.4610</td> <td>    0.154</td> <td>   -2.989</td> <td> 0.003</td> <td>   -0.765</td> <td>   -0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[1]</th> <td>    0.0010</td> <td>    0.001</td> <td>    0.831</td> <td> 0.407</td> <td>   -0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[2]</th> <td> 7.515e-07</td> <td> 3.16e-06</td> <td>    0.238</td> <td> 0.812</td> <td>-5.48e-06</td> <td> 6.98e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.392</td> <th>  Durbin-Watson:     </th> <td>   1.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  16.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.365</td> <th>  Prob(JB):          </th> <td>0.000287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.211</td> <th>  Cond. No.          </th> <td>4.71e+07</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.71e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.705\n",
       "Model:                            OLS   Adj. R-squared:                  0.701\n",
       "Method:                 Least Squares   F-statistic:                     153.0\n",
       "Date:                Sat, 21 Jan 2023   Prob (F-statistic):           1.14e-50\n",
       "Time:                        19:02:49   Log-Likelihood:                -568.69\n",
       "No. Observations:                 196   AIC:                             1145.\n",
       "Df Residuals:                     192   BIC:                             1158.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================================================================\n",
       "                                                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                    57.5977      5.928      9.715      0.000      45.904      69.291\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[0]    -0.4610      0.154     -2.989      0.003      -0.765      -0.157\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[1]     0.0010      0.001      0.831      0.407      -0.001       0.004\n",
       "polynomial_features.fit_transform(np.array(horsepower).reshape(-1, 1))[2]  7.515e-07   3.16e-06      0.238      0.812   -5.48e-06    6.98e-06\n",
       "==============================================================================\n",
       "Omnibus:                       11.392   Durbin-Watson:                   1.228\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               16.312\n",
       "Skew:                           0.365   Prob(JB):                     0.000287\n",
       "Kurtosis:                       4.211   Cond. No.                     4.71e+07\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.71e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(3, include_bias=False)\n",
    "\n",
    "lm_model3_poly_feats  = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(horsepower).reshape(-1,1))', data = auto_df_no_gaps, subset=train_idx)\n",
    "lm_fit3_poly_feats = lm_model3_poly_feats.fit(method='qr')\n",
    "\n",
    "lm_fit3_poly_feats.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ef11e-9398-413a-8e53-cc5611a7b98d",
   "metadata": {},
   "source": [
    "**Incomplete: The models are not the same**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132a83e-20c3-472f-963b-a0b1867c9a3d",
   "metadata": {},
   "source": [
    "##### Checking MSEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c0ff0-f0bc-4a97-900c-16ce5fc82dc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Checking MSEs using ortho_poly_fit and smf.ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79bc1836-6937-4aba-b939-31201aeb2b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 18.79401\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "mean((mpg - predict(lm.fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a85bce1-e75e-4ac9-b358-62ac27e29b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.743175316050696"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3_ortho_poly = lm_fit3_ortho_poly.predict(auto_df_no_gaps[~auto_train_mask_no_gaps])\n",
    "\n",
    "((pred3_ortho_poly - auto_df_no_gaps[~auto_train_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769f6e4-f4b3-42a3-bb66-7087fb27ddb0",
   "metadata": {},
   "source": [
    "###### Checking MSEs using PolynomialFeatures and smf.ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b71aaca-849c-47b3-89d7-00cb8d578a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.794006797394548"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3_poly_feats = lm_fit3_poly_feats.predict(auto_df_no_gaps[~auto_train_mask_no_gaps])\n",
    "\n",
    "((pred3_poly_feats - auto_df_no_gaps[~auto_train_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f8be7-884c-4e94-b71f-1d9bdd24bae8",
   "metadata": {},
   "source": [
    "**Complete: The MSE from using PolynomialFeatures with smf.ols matches in Python and R, despite the models between Python and R not entirely matching, due to the difference in inputs where poly returns orthogonalized vectors while PolynomialFeatures doesn't**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd992fe1-476b-4d2a-84f4-390138048a1c",
   "metadata": {},
   "source": [
    "### Generating new training indices and reealuting MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a021dfd-4251-4541-865d-5af6acf5ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 25.72651\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(2)\n",
    "train <- sample(392, 196)\n",
    "lm.fit <- lm(mpg ~ horsepower, subset = train)\n",
    "mean((mpg - predict(lm.fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89d1fb51-a6ab-4b74-b3e2-7cf1930f817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robjects.r(\"\"\"\n",
    "library(ISLR2)\n",
    "set.seed(2)\n",
    "train <- sample(392, 196)\n",
    "\"\"\")\n",
    "\n",
    "new_train_idx = np.array(data)\n",
    "new_train_idx = np.sort(new_train_idx)\n",
    "\n",
    "new_auto_train_mask_no_gaps = auto_df_no_gaps.index.isin(new_train_idx)\n",
    "new_auto_test_mask_no_gaps = ~new_auto_train_mask_no_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb54b82c-c2a0-4ed4-89d9-1105a584aa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.726510644813906"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_model = smf.ols(formula='mpg ~ horsepower', data = auto_df_no_gaps, subset = new_train_idx)\n",
    "\n",
    "lm_fit = lm_model.fit()\n",
    "\n",
    "pred = lm_fit.predict(auto_df_no_gaps[~new_auto_train_mask_no_gaps]['horsepower'])\n",
    "\n",
    "((pred - auto_df_no_gaps[~new_auto_train_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e699d4-a196-4a0a-b2b5-c67623b265a3",
   "metadata": {},
   "source": [
    "#### Polynomial Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff19e6b-77c8-4d2e-a7f4-23f3e9da5ba5",
   "metadata": {},
   "source": [
    "##### 2nd Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e547520b-00d3-4f39-a3c0-1e6e178bc55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 20.43036\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
    "mean((mpg - predict(lm.fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8071ee1f-4a51-4017-979f-506ba9f144f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.430364274146303"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(2, include_bias=False)\n",
    "\n",
    "new_lm_model2_poly_feats  = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(horsepower).reshape(-1,1))', data = auto_df_no_gaps, subset=new_train_idx)\n",
    "new_lm_fit2_poly_feats = new_lm_model2_poly_feats.fit(method='qr')\n",
    "\n",
    "new_pred2_poly_feats = new_lm_fit2_poly_feats.predict(auto_df_no_gaps[new_auto_test_mask_no_gaps]['horsepower'])\n",
    "\n",
    "((new_pred2_poly_feats - auto_df_no_gaps[new_auto_test_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9605f01-5eab-4ab0-a5a5-c5129a6f3e96",
   "metadata": {},
   "source": [
    "**Complete: Same MSE in R and Python despite models being slightly different due to input vectors not being orthogonalized in Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd825d5-e6da-44d2-b6fe-6acc49e86852",
   "metadata": {},
   "source": [
    "##### 3rd Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2361356c-7c76-4faa-9c49-12c2efc560e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 20.38533\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)\n",
    "mean((mpg - predict(lm.fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94a6d5a0-4da8-4999-b591-60aa2e90b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.385326863877566"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## include_bias=False so that an intercept column is not returned\n",
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(3, include_bias=False)\n",
    "\n",
    "new_lm_model3_poly_feats  = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(horsepower).reshape(-1,1))', data = auto_df_no_gaps, subset=new_train_idx)\n",
    "new_lm_fit3_poly_feats = new_lm_model3_poly_feats.fit(method='qr')\n",
    "\n",
    "new_pred3_poly_feats = new_lm_fit3_poly_feats.predict(auto_df_no_gaps[new_auto_test_mask_no_gaps]['horsepower'])\n",
    "\n",
    "((new_pred3_poly_feats - auto_df_no_gaps[new_auto_test_mask_no_gaps]['mpg'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68079c29-7ca9-45ad-92d1-9491e388603f",
   "metadata": {},
   "source": [
    "**Complete: Same MSE in R and Python despite models being slightly different due to input vectors not being orthogonalized in Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d8280-82bf-42e4-8f22-759c818387b9",
   "metadata": {},
   "source": [
    "## 5.3.2 Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6433786-21b8-4a7f-bbdc-c316fad34835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 39.9358610  -0.1578447 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "glm.fit <- glm(mpg ~ horsepower, data = Auto)\n",
    "coef(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c59d2c81-8019-4a72-a237-9ad6ef074e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_model = smf.glm(formula='mpg ~ horsepower', data=auto_df_no_gaps)\n",
    "glm_fit = glm_model.fit()\n",
    "glm_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63621bdb-fb64-402e-a65e-aa491b66bfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 39.9358610  -0.1578447 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "lm.fit <- lm(mpg ~ horsepower, data = Auto)\n",
    "coef(lm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bf22026-6c88-4d2f-b34b-04a390c2d150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_model = smf.ols(formula = 'mpg ~ horsepower', data=auto_df_no_gaps)\n",
    "lm_fit = lm_model.fit()\n",
    "lm_fit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71b55b-33d7-49ea-8cff-eed823823a25",
   "metadata": {},
   "source": [
    "### Checking that cv.glm in R and cross_val_score with smf.glm in Python produce same results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01f576fa-f9d7-45e9-94ec-ab9d24c98813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 24.23151 24.23114\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(boot)\n",
    "glm.fit <- glm(mpg ~ horsepower, data = Auto)\n",
    "cv.err <- cv.glm(Auto, glm.fit)\n",
    "cv.err$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd98575-97cd-40f5-bae2-19b8cef95a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm_model = smf.glm(formula='mpg ~ horsepower', data=auto_df_no_gaps)\n",
    "# glm_fit = glm_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d20f8584-e406-41bb-aebc-b3e002e47126",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original Code and usage for the modified code in the cell below\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# class SMWrapper(BaseEstimator, RegressorMixin):\n",
    "#     \"\"\" A universal sklearn-style wrapper for statsmodels regressors \"\"\"\n",
    "#     def __init__(self, model_class, fit_intercept=True):\n",
    "#         self.model_class = model_class\n",
    "#         self.fit_intercept = fit_intercept\n",
    "#     def fit(self, X, y):\n",
    "#         if self.fit_intercept:\n",
    "#             X = sm.add_constant(X)\n",
    "#         self.model_ = self.model_class(y, X)\n",
    "#         self.results_ = self.model_.fit()\n",
    "#         return self\n",
    "#     def predict(self, X):\n",
    "#         if self.fit_intercept:\n",
    "#             X = sm.add_constant(X)\n",
    "#         return self.results_.predict(X)\n",
    "\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# X, y = make_regression(random_state=1, n_samples=300, noise=100)\n",
    "\n",
    "# print(cross_val_score(SMWrapper(sm.OLS), X, y, scoring='r2'))\n",
    "# print(cross_val_score(LinearRegression(), X, y, scoring='r2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9c93027-14f4-4b66-97e7-2a7ab676ad24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## The main code for SMWrapper was taken from: https://stackoverflow.com/questions/41045752/using-statsmodel-estimations-with-scikit-learn-cross-validation-is-it-possible, however I adapted it slightly to be able to work with the smf.glm command.  The changes are as follows:\n",
    "## 1) I had to create a self.formula attribute for use in creating the model in the fit method.\n",
    "\n",
    "## 2) I had to concatenate X and y into a pandas df to be passed when creating the model in the fit method.\n",
    "\n",
    "## 3) When creating the model, I have to pass self.formula from step 1) and the pandas df from step 2)\n",
    "\n",
    "## 4) I had to convert X into a pandas df when making predictions using the predict method.\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class SMWrapper(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" A universal sklearn-style wrapper for statsmodels regressors \"\"\"\n",
    "    def __init__(self, model_class, formula, fit_intercept=True):\n",
    "        self.model_class = model_class\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.formula = formula  ## 1)\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        data = pd.DataFrame(np.concatenate((X,y), axis=1), \n",
    "                            columns=['horsepower', 'mpg']) ## 2)\n",
    "        self.model_ = self.model_class(self.formula, data) ## 3)\n",
    "        self.results_ = self.model_.fit()\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        horsepower = pd.DataFrame(X, columns = ['horsepower']) ##4)\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(horsepower)\n",
    "        return self.results_.predict(horsepower)\n",
    "\n",
    "\n",
    "X = auto_df_no_gaps['horsepower'].values.reshape(-1,1)\n",
    "y = auto_df_no_gaps['mpg'].values.reshape(-1,1)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "\n",
    "scores = cross_val_score(estimator = SMWrapper(smf.glm, \n",
    "                                      formula='mpg ~ horsepower',\n",
    "                                      fit_intercept=False), \n",
    "                            X=X, y=y, cv = loo, scoring = 'neg_mean_squared_error', error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c19176f9-34cc-49b5-ba0e-434015e9108b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.23151351792922"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b075ece-ae3a-402d-a3a0-cccd5a4a0dd8",
   "metadata": {},
   "source": [
    "**Complete: cv.glm in R and cross_val_score with smf.glm in Python produce same results, although it was somewhat difficult to replicate because cross_val_score is from sklearn and smf.glm is from statsmodels, which makes compatibility between them difficult.  Using the SMWrapper class overcomes this, but modifications need to be made to that class which don't scale well with my current solution.  It's probably easier to generate a model using the sklearn library, so that compatibility isn't an issue when using cross_val_score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f755b4-8445-4f1a-82bc-185d420e69c7",
   "metadata": {},
   "source": [
    "### Checking that cv.glm in R and cross_val_score with LinearRegression in Python produce same results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d5f15d5-ae38-4772-826b-86308b47d28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929226"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## http://www.science.smith.edu/~jcrouser/SDS293/labs/lab7-py.html\n",
    "\n",
    "X = auto_df_no_gaps['horsepower'].values.reshape(-1,1)\n",
    "y = auto_df_no_gaps['mpg'].values.reshape(-1,1)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "skl_lm_model = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "scores = cross_val_score(skl_lm_model, X, y, cv = loo, scoring='neg_mean_squared_error')\n",
    "\n",
    "np.mean(np.abs(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29e451-a594-439a-bd4e-4904ccf48195",
   "metadata": {},
   "source": [
    "**Complete: Same MSE and easier to implement since LinearRegression is a sklearn object, so it's compatible with cross_val_score, also from the sklearn library**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69002c6-8735-43cb-95e2-a10379b450ca",
   "metadata": {},
   "source": [
    "### Polynomial Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "60101c94-1d28-403f-8548-9a95295bf16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 24.23151 19.24821 19.33498 19.42443 19.03321 18.97864 18.83305 18.96115\n",
      " [9] 19.06863 19.49093\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "cv.error <- rep(0, 10)\n",
    "for (i in 1:10) {\n",
    "    glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "    cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]\n",
    "}\n",
    "cv.error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3718d73-e227-4431-849a-8dadd4fee674",
   "metadata": {},
   "source": [
    "#### 2nd Degree Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32813407-56c6-4d1f-9cd1-4d6a5e9f1a57",
   "metadata": {},
   "source": [
    "##### Checking that cv.glm in R and cross_val_score with smf.glm in Python produce same results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e991073-d4ac-4f6b-b470-58ff2efaa2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ortho_poly_predict(x, alpha, norm2, degree = 1):\n",
    "    x = np.asarray(x).flatten()\n",
    "    n = degree + 1\n",
    "    Z = np.empty((len(x), n))\n",
    "    Z[:,0] = 1\n",
    "    if degree > 0:\n",
    "        Z[:, 1] = x - alpha[0]\n",
    "    if degree > 1:\n",
    "      for i in np.arange(1,degree):\n",
    "          Z[:, i+1] = (x - alpha[i]) * Z[:, i] - (norm2[i] / norm2[i-1]) * Z[:, i-1]\n",
    "    Z /= np.sqrt(norm2)\n",
    "    return Z[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb9a9c41-7115-4388-9512-b18bd5de0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As much as I'd like to cross_validate using the smf.glm function to replicate the R code, it's going to be difficult to iterate over different powers for the polynomial fit unless I can figure out a way to use the ortho_poly_fit() in the formula= parameter when calling to SMWrapper, otherwise I have to manually type out the formula 'mpg ~ hp1 + hp2 + ...' and also modify the SWMrapper class accordingly in the SWMrapper fit and predict methods...It's probably better to switch to sklearn at this point and using LinearRegression and PolynomialFeatures instead.\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class SMWrapper(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" A universal sklearn-style wrapper for statsmodels regressors \"\"\"\n",
    "    def __init__(self, model_class, formula, fit_intercept=True):\n",
    "        self.model_class = model_class\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.formula = formula  ## 1)\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        X, self.norm2_, self.alpha_ = ortho_poly_fit(X, 2)\n",
    "        \n",
    "        \n",
    "        data = pd.DataFrame(np.concatenate((X,y), axis=1), \n",
    "                            columns=['hp1', 'hp2', 'mpg']) ## 2)\n",
    "        self.model_ = self.model_class(self.formula, data) ## 3)\n",
    "        self.results_ = self.model_.fit()\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        X = ortho_poly_predict(X, self.alpha_, self.norm2_, 2)\n",
    "        horsepower = pd.DataFrame(X, columns = ['hp1', 'hp2']) ##4)\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(horsepower)\n",
    "        return self.results_.predict(horsepower)\n",
    "\n",
    "\n",
    "X = auto_df_no_gaps['horsepower'].values.reshape(-1,1)\n",
    "y = auto_df_no_gaps['mpg'].values.reshape(-1,1)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "\n",
    "scores = cross_val_score(estimator = SMWrapper(smf.glm, \n",
    "                                      formula='mpg ~ hp1 + hp2',\n",
    "                                      fit_intercept=False), \n",
    "                            X=X, y=y, cv = loo, scoring = 'neg_mean_squared_error', error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4dd9067d-1b29-4f6c-ab25-a93764b74fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.24821312448969"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7044e1-c308-48fd-89a4-f93dbae1e78a",
   "metadata": {},
   "source": [
    "**Complete: With further modification to the SMWrapper class, I was able to get the same MSE as R, however the solution doesn't scale well when trying to iterate over polynomials with different degrees.  It's much easier to stay in the sklearn library with LinearRegression and cross_val_score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054493b-91a6-453d-919c-b8be1fcfca42",
   "metadata": {},
   "source": [
    "#### Checking MSE over polynomials with various degrees matches with R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d5eb1f17-cc96-4ed2-b829-1ce16de04fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_error = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    polynomial_features = sklearn.preprocessing.PolynomialFeatures(i, include_bias=False)\n",
    "\n",
    "    scores = cross_val_score(skl_lm_model, polynomial_features.fit_transform(X), y, cv = loo, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    mean_score = np.mean(np.abs(scores))\n",
    "    \n",
    "    cv_error.append(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3279974-e14b-4612-b73a-50a1d9f44d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.231513517929226,\n",
       " 19.24821312448967,\n",
       " 19.33498406402931,\n",
       " 19.42443031024277,\n",
       " 19.03321248615882,\n",
       " 18.97863406819667,\n",
       " 19.129480449254846,\n",
       " 19.224150660848743,\n",
       " 19.133322843461364,\n",
       " 18.93976572079586]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496c4eb-9f2e-44bf-a7e9-13c9ae941fe4",
   "metadata": {},
   "source": [
    "**The MSEs match closely in Python and R.  All but the last 4 entries match exactly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f426b-17f0-494e-8578-5a8265b30d8a",
   "metadata": {},
   "source": [
    "## 5.3.3 k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "462759e9-4db6-443e-80cf-507dd0968aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666\n",
      " [9] 18.87013 20.95520\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(17)\n",
    "cv.error.10 <- rep(0, 10)\n",
    "for (i in 1:10) {\n",
    "    glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "    cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]\n",
    "}\n",
    "cv.error.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19219a18-a8a5-409c-96ec-98f7d06827c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_error_10 = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    polynomial_features = sklearn.preprocessing.PolynomialFeatures(i, include_bias=False)\n",
    "\n",
    "    scores = cross_val_score(skl_lm_model, polynomial_features.fit_transform(X), y, cv = 10, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    mean_score = np.mean(np.abs(scores))\n",
    "    \n",
    "    cv_error_10.append(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d761a4a0-3e8f-45c8-bb6b-a22b1e34e3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27.439933652339874,\n",
       " 21.235840055802225,\n",
       " 21.33660618322788,\n",
       " 21.35388698195473,\n",
       " 20.905641650770082,\n",
       " 20.779180086179668,\n",
       " 20.990939391569672,\n",
       " 21.077615424551695,\n",
       " 21.036905853431772,\n",
       " 20.977623972381583]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059d0e1-c6d0-40fe-b965-518dc90669af",
   "metadata": {},
   "source": [
    "**Because the folds are randomly generated, the folds generated from cv.glm in R are likely to be different than the folds generates from cross_val_score in Python and we shouldn't expect the bootstrap MSEs to match, but we'd expect them to be similar, which they are.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483edd91-662b-43d0-a5c7-b45cc2b7ddd1",
   "metadata": {},
   "source": [
    "## 5.3.4 The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6048885-19be-4e43-9d55-126ebf58e1a9",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Statistic of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "498f4fff-d285-487c-8e8e-761ae6e33547",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "alpha.fn <- function(data, index) {\n",
    "    X <- data$X[index]\n",
    "    Y <- data$Y[index]\n",
    "    (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e819ff38-856a-4c79-8e3b-580db7e65920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.5758321\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "alpha.fn(Portfolio, 1:100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cb230e72-101a-4606-8c8f-630f58f5473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfolio_df = pd.read_csv(\"../../../datasets/Portfolio.csv\")\n",
    "pfolio_df = pfolio_df.set_index(np.arange(1, pfolio_df.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18e249ca-2a09-4664-93e8-01874e3afb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_fn(data, index):\n",
    "    X = data.loc[index]['X']\n",
    "    Y = data.loc[index]['Y']\n",
    "    var_x = np.var(X, ddof=1)\n",
    "    var_y = np.var(Y, ddof=1)\n",
    "    cov_x_y = np.cov(X, Y, ddof=1)[0][1]\n",
    "    \n",
    "    return (var_y - cov_x_y) / (var_x + var_y - 2 * cov_x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "adbe2647-b26f-414e-8ae5-47f2c1030611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758320745928298"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_fn(pfolio_df, np.arange(1,101))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea109847-92bd-4d8d-b2fc-4b06ccb030b7",
   "metadata": {},
   "source": [
    "#### Figuring out how to match the variance and covariance calculated in R and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4101ba2f-2376-478b-a942-87e1d3237d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pfolio_df[1:10]['X']\n",
    "Y = pfolio_df[1:10]['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e6b780a-e17e-4d15-a231-4254be1d3a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1.128642\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "var(Portfolio$X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b0c4ea15-1cd6-4694-bf2b-65f7ff715d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1286423581187572"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using ddof alters the formula when calculating the variance because the denominator = N - ddof.  When ddof=1, np.var calculates the unbiased estimate of the variance (the sample variance) as it divides by N - 1.  We need to do this in order to replicate the same values as R does.\n",
    "np.var(pfolio_df['X'], ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dce8ed9d-68fe-457a-adc6-d6f29da6744e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1286423581187572"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfolio_df['X'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "80dff2ed-86f5-4339-a669-19b7af369f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1.308237\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "var(Portfolio$Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f419810-9a56-46e1-84a7-7acdd5ff175e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3082374688243965"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using ddof alters the formula when calculating the variance because the denominator = N - ddof.  When ddof=1, np.var calculates the unbiased estimate of the variance (the sample variance) as it divides by N - 1.  We need to do this in order to replicate the same values as R does.\n",
    "np.var(pfolio_df['Y'], ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b10c1aad-dbc4-468c-9b5d-3f8f6d6981a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3082374688243965"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfolio_df['Y'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5c8f1544-8752-46b9-b322-417611d95631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.6263583\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "cov(Portfolio$X, Portfolio$Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f41e7f0-658b-4af9-becb-da529c160d02",
   "metadata": {},
   "source": [
    "Covariance Matrix:\n",
    "$$\\Bigl(\n",
    "\\begin{array}{rr}\n",
    "\\sigma(x,x)&\\sigma(x,y) \\\\\n",
    "\\sigma(y, x)&\\sigma(y,y)\n",
    "\\end{array}\n",
    "\\Bigr)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb33cbfa-7841-43b0-bc8d-1dcdb1e6f9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263582921063724"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## np.cov returns the covariance matrix see above.  Where we only care about the covariance of x and y, so we have to index into the matrix to extract only that value\n",
    "np.cov(pfolio_df['X'], pfolio_df['Y'])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bebb3c0b-be93-418c-b4b4-1095b44ffedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.5385326\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(7)\n",
    "alpha.fn(Portfolio, sample(100, 100, replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7c68087c-47c6-4285-9984-93547dfa2f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1]   2   3   4   5   6   6   8   8   8   8   9  10  11  12  12  15  16  16\n",
      " [19]  17  18  18  20  21  21  22  22  22  22  26  28  31  31  31  32  32  32\n",
      " [37]  33  34  34  36  38  38  38  39  40  40  40  41  41  42  43  43  44  44\n",
      " [55]  45  46  47  48  50  51  53  53  55  56  58  58  59  59  59  59  62  64\n",
      " [73]  66  67  67  68  72  72  72  73  74  75  77  78  79  80  81  83  87  87\n",
      " [91]  88  88  88  90  90  92  93  94  97 100\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(7)\n",
    "sort(sample(100, 100, replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e24bd8f-f495-4201-9664-7a94f10e910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robjects.r(\"\"\"\n",
    "set.seed(7)\n",
    "train <- sample(100, 100, replace=T)\n",
    "\"\"\")\n",
    "\n",
    "bstrap_idx = np.array(data)\n",
    "bstrap_idx = np.sort(bstrap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a7753848-79c3-4579-ba09-dccb79be8438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385325919467925"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_fn(pfolio_df, bstrap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0c62bb2d-3e5f-44c3-aac8-606ce540a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
      "\n",
      "\n",
      "Call:\n",
      "boot(data = Portfolio, statistic = alpha.fn, R = 1000)\n",
      "\n",
      "\n",
      "Bootstrap Statistics :\n",
      "     original       bias    std. error\n",
      "t1* 0.5758321 0.0007959475  0.08969074\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot(Portfolio, alpha.fn, R = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "263a1707-bc5f-41bc-8345-b65fba303bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Alpha: 0.5758320745928298\n",
      "Alpha Bias: -0.0015445354807817058\n",
      "Alpha Std: 0.08933533071965215\n"
     ]
    }
   ],
   "source": [
    "## Note: the boot package from R automatically creates bootstrap samples of length n, where n = the number of observations in the dataset you pass to boot.  In order to mimic that behavior in Python, we need to use np.random.choice n times.\n",
    "\n",
    "alphas = []\n",
    "n = pfolio_df.shape[0]\n",
    "for _ in range(1000):\n",
    "    idx = np.random.choice(np.arange(1, n+1), n)\n",
    "    alpha = alpha_fn(pfolio_df, idx)\n",
    "    alphas.append(alpha)\n",
    "    \n",
    "original_alpha = alpha_fn(pfolio_df, np.arange(1, n+1))\n",
    "alpha_bstrap_mean = np.mean(alphas)\n",
    "alpha_bstrap_std = np.std(alphas)\n",
    "\n",
    "## Bias = bootstrap realization of the statistic - the original statistic from the original data\n",
    "alpha_bias = alpha_bstrap_mean - original_alpha\n",
    "\n",
    "print(f'Original Alpha: {original_alpha}')\n",
    "print(f'Alpha Bias: {alpha_bias}')\n",
    "print(f'Alpha Std: {alpha_bstrap_std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cb5cd-7edb-4ed9-89f3-a176fdc94efb",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1be0656c-b54f-42ba-932c-8441a8afc74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 39.9358610  -0.1578447 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot.fn <- function(data, index)\n",
    "    coef(lm(mpg ~ horsepower, data = data, subset = index))\n",
    "boot.fn(Auto, 1:392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e658f53-75f8-490e-bebf-3bbde0567c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_fn(data, index):\n",
    "    model = smf.glm(formula = 'mpg ~ horsepower', data = data, subset = index)\n",
    "    fit = model.fit()\n",
    "    coefficients = fit.params\n",
    "    \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f9e43d20-510a-46f5-9d2c-d80bea79259d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_fn(auto_df_no_gaps, np.arange(1, 393))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "921c4cec-f786-47b3-add4-76a2b7caec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 40.3404517  -0.1634868 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "set.seed(1)\n",
    "boot.fn(Auto, sample(392, 392, replace = T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7ffbbb87-ae69-415c-a942-a0dd7660bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robjects.r(\"\"\"\n",
    "set.seed(1)\n",
    "samp <- sample(392, 392, replace=T)\n",
    "\"\"\")\n",
    "\n",
    "bstrap_idx = np.array(data)\n",
    "bstrap_idx = np.sort(bstrap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "783cf2dd-31b1-409e-8c90-e754635bc3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     40.340452\n",
       "horsepower    -0.163487\n",
       "dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_fn(auto_df_no_gaps, bstrap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8fb99a65-4c45-4849-8869-4947bfc805e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 40.1186906  -0.1577063 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot.fn(Auto, sample(392, 392, replace = T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c220c1d-c1a1-4997-811d-bfb48ee16607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     41.232962\n",
       "horsepower    -0.165045\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(np.arange(1,393), 392)\n",
    "boot_fn(auto_df_no_gaps, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d222398-7bf1-491f-8b95-12d9e8df4887",
   "metadata": {},
   "source": [
    "#### Figuring out how the bias is calculated using boot in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e6c46acb-f85f-4b9d-9801-258790948776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         [,1]       [,2]\n",
      "[1,] 41.08282 -0.1672521\n",
      "[2,] 39.08086 -0.1529244\n",
      "[3,] 39.86280 -0.1584696\n",
      "[4,] 38.53024 -0.1472011\n",
      "[5,] 41.37322 -0.1712221\n",
      "[6,] 41.10563 -0.1665629\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "myBootstrap <- boot(Auto, boot.fn, 1000)\n",
    "\n",
    "head(myBootstrap$t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "89aa69a4-61d0-4839-9e4e-effffb75a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)  horsepower \n",
      " 39.9358610  -0.1578447 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "myBootstrap$t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33961717-730e-4e98-99b4-e009c2ca701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
      "\n",
      "\n",
      "Call:\n",
      "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
      "\n",
      "\n",
      "Bootstrap Statistics :\n",
      "      original        bias    std. error\n",
      "t1* 39.9358610  0.0269869095 0.855401374\n",
      "t2* -0.1578447 -0.0002153158 0.007404461\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "myBootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cc0801e5-9687-4404-bf25-15daba2f6f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept) \n",
      "   39.93586 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "myBootstrap$t0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "72f1280e-5d06-443d-9b00-0976a7c7b64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept) \n",
      " 0.02698691 \n"
     ]
    }
   ],
   "source": [
    "# Intercept Bias\n",
    "%%R\n",
    "mean(myBootstrap$t[,1]) - myBootstrap$t0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2a2a7868-fb7c-44e1-bf2f-9d5b3dfa5d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   horsepower \n",
      "-0.0002153158 \n"
     ]
    }
   ],
   "source": [
    "# Horsepower Bias\n",
    "%%R\n",
    "mean(myBootstrap$t[,2]) - myBootstrap$t0[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "58f2d537-c07b-4fb1-bfe7-8c3ddb3d5092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
      "\n",
      "\n",
      "Call:\n",
      "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
      "\n",
      "\n",
      "Bootstrap Statistics :\n",
      "      original        bias    std. error\n",
      "t1* 39.9358610  0.0063436842 0.851685494\n",
      "t2* -0.1578447 -0.0002332595 0.007326806\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c920b000-9519-45e6-a0d3-75c547d49ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Intercept: 39.93586102117048\n",
      "Bstrap Intercept Bias: 0.008042435746091314\n",
      "Bstrap Intercept Std: 0.8621755340747947\n",
      "\n",
      "Original Slope: -0.15784473335365357\n",
      "Bstrap Slope Bias: -8.1662740625571e-05\n",
      "Bstrap Slope Std: 0.0073593483874999695\n"
     ]
    }
   ],
   "source": [
    "intercepts = []\n",
    "slopes = []\n",
    "\n",
    "n = auto_df_no_gaps.shape[0]\n",
    "\n",
    "for _ in range(1000):\n",
    "    idx = np.random.choice(np.arange(1, n+1), n)\n",
    "    param = boot_fn(auto_df_no_gaps, idx)\n",
    "    intercept = param[0]\n",
    "    slope = param[1]\n",
    "    intercepts.append(intercept)\n",
    "    slopes.append(slope)\n",
    "\n",
    "original_intercept = boot_fn(auto_df_no_gaps, np.arange(1, 393))[0]\n",
    "original_slope = boot_fn(auto_df_no_gaps, np.arange(1, 393))[1]\n",
    "intercept_bstrap_mean = np.mean(intercepts)\n",
    "intercept_bstrap_std = np.std(intercepts)\n",
    "slope_bstrap_mean = np.mean(slopes)\n",
    "slope_bstrap_std = np.std(slopes)\n",
    "\n",
    "## Bias = bootstrap realization of the statistic - the original statistic from the original data\n",
    "## bias for intercepts\n",
    "intercept_bias = intercept_bstrap_mean - original_intercept\n",
    "\n",
    "## bias for slopes\n",
    "slope_bias = slope_bstrap_mean - original_slope\n",
    "\n",
    "print(f'Original Intercept: {original_intercept}')\n",
    "print(f'Bstrap Intercept Bias: {intercept_bias}')\n",
    "print(f'Bstrap Intercept Std: {intercept_bstrap_std}')\n",
    "print()\n",
    "print(f'Original Slope: {original_slope}')\n",
    "print(f'Bstrap Slope Bias: {slope_bias}')\n",
    "print(f'Bstrap Slope Std: {slope_bstrap_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "57299887-57d8-496a-9544-8e543f979b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Estimate  Std. Error   t value      Pr(>|t|)\n",
      "(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\n",
      "horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary(lm(mpg ~ horsepower, data = Auto))$coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e8027c3c-4560-44b9-b4ba-28c86eb12b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>39.9359</td>\n",
       "      <td>0.717</td>\n",
       "      <td>55.660</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.1578</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-24.489</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coef  std err       t  P>|t|\n",
       "Intercept   39.9359    0.717  55.660    0.0\n",
       "horsepower  -0.1578    0.006 -24.489    0.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://stackoverflow.com/questions/51734180/converting-statsmodels-summary-object-to-pandas-dataframe\n",
    "\n",
    "results = smf.ols(formula = 'mpg ~ horsepower', data = auto_df_no_gaps).fit().summary().tables[1]\n",
    "\n",
    "results_as_html = results.as_html()\n",
    "results_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "results_df[['coef', 'std err', 't', 'P>|t|']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "16bdc454-405e-42ac-a9c6-1e0d6f89d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
      "\n",
      "\n",
      "Call:\n",
      "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
      "\n",
      "\n",
      "Bootstrap Statistics :\n",
      "        original        bias     std. error\n",
      "t1* 56.900099702  3.511640e-02 2.0300222526\n",
      "t2* -0.466189630 -7.080834e-04 0.0324241984\n",
      "t3*  0.001230536  2.840324e-06 0.0001172164\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "boot.fn <- function(data, index)\n",
    "    coef(\n",
    "      lm(mpg ~ horsepower + I(horsepower^2),\n",
    "        data = data, subset = index)\n",
    "    )\n",
    "\n",
    "set.seed(1)\n",
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "06ec9a20-07c7-4555-8ca7-7e31483f7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What does I() do in the formula: https://stackoverflow.com/questions/24192428/what-does-the-capital-letter-i-in-r-linear-regression-formula-mean\n",
    "\n",
    "def boot_fn(data, index):\n",
    "    model = smf.ols(formula='mpg ~ horsepower + I(horsepower**2)', \n",
    "                    data=data, \n",
    "                    subset=index)\n",
    "    fit = model.fit()\n",
    "    params = fit.params\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ecc3eca3-2299-462f-b21b-3dcba0b2eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = []\n",
    "hp_1s = []\n",
    "hp_2s = []\n",
    "\n",
    "n = auto_df_no_gaps.shape[0]\n",
    "\n",
    "for _ in range(1000):\n",
    "    idx = np.random.choice(np.arange(1, n+1), n)\n",
    "    param = boot_fn(auto_df_no_gaps, idx)\n",
    "    intercept = param[0]\n",
    "    hp_1 = param[1]\n",
    "    hp_2 = param[2]\n",
    "    intercepts.append(intercept)\n",
    "    hp_1s.append(hp_1)\n",
    "    hp_2s.append(hp_2)\n",
    "\n",
    "original_intercept = boot_fn(auto_df_no_gaps, np.arange(1, 393))[0]\n",
    "original_hp_1 = boot_fn(auto_df_no_gaps, np.arange(1, 393))[1]\n",
    "original_hp_2 = boot_fn(auto_df_no_gaps, np.arange(1, 393))[2]\n",
    "\n",
    "intercept_bstrap_mean = np.mean(intercepts)\n",
    "intercept_bstrap_std = np.std(intercepts)\n",
    "\n",
    "hp_1_bstrap_mean = np.mean(hp_1s)\n",
    "hp_1_bstrap_std = np.std(hp_1s)\n",
    "\n",
    "hp_2_bstrap_mean = np.mean(hp_2s)\n",
    "hp_2_bstrap_std = np.std(hp_2s)\n",
    "\n",
    "## Bias = bootstrap realization of the statistic - the original statistic from the original data\n",
    "## bias for intercepts\n",
    "intercept_bias = intercept_bstrap_mean - original_intercept\n",
    "\n",
    "## bias for horsepower\n",
    "hp_1_bias = hp_1_bstrap_mean - original_hp_1\n",
    "\n",
    "## bias for horsepower**2\n",
    "hp_2_bias = hp_2_bstrap_mean - original_hp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4c3d9770-8fc5-443e-803a-7265c31dcac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Intercept: 56.90009970211517\n",
      "Bstrap Intercept Bias: 0.0132612933591858\n",
      "Bstrap Intercept Std: 2.0662318312178485\n",
      "\n",
      "Original Slope: -0.46618962994736257\n",
      "Bstrap horsepower Bias: -0.00025808661667581223\n",
      "Bstrap horsepower Std: 0.03308139950767811\n",
      "\n",
      "Original Slope: 0.0012305361007737656\n",
      "Bstrap horsepower**2 Bias: 1.4277834845274982e-06\n",
      "Bstrap horsepower**2 Std: 0.00012030349685526833\n"
     ]
    }
   ],
   "source": [
    "print(f'Original Intercept: {original_intercept}')\n",
    "print(f'Bstrap Intercept Bias: {intercept_bias}')\n",
    "print(f'Bstrap Intercept Std: {intercept_bstrap_std}')\n",
    "print()\n",
    "print(f'Original Slope: {original_hp_1}')\n",
    "print(f'Bstrap horsepower Bias: {hp_1_bias}')\n",
    "print(f'Bstrap horsepower Std: {hp_1_bstrap_std}')\n",
    "print()\n",
    "print(f'Original Slope: {original_hp_2}')\n",
    "print(f'Bstrap horsepower**2 Bias: {hp_2_bias}')\n",
    "print(f'Bstrap horsepower**2 Std: {hp_2_bstrap_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "028fbcc0-346a-4e79-863f-3928410c49bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Estimate   Std. Error   t value      Pr(>|t|)\n",
      "(Intercept)     56.900099702 1.8004268063  31.60367 1.740911e-109\n",
      "horsepower      -0.466189630 0.0311246171 -14.97816  2.289429e-40\n",
      "I(horsepower^2)  0.001230536 0.0001220759  10.08009  2.196340e-21\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary(\n",
    "    lm(mpg ~ horsepower + I(horsepower^2), data = Auto)\n",
    ")$coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e0c20474-381c-451e-b372-0de82fb82a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>56.9001</td>\n",
       "      <td>1.800</td>\n",
       "      <td>31.604</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.4662</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-14.978</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I(horsepower ** 2)</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       coef  std err       t  P>|t|\n",
       "Intercept           56.9001    1.800  31.604    0.0\n",
       "horsepower          -0.4662    0.031 -14.978    0.0\n",
       "I(horsepower ** 2)   0.0012    0.000  10.080    0.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.ols(formula = 'mpg ~ horsepower + I(horsepower**2)',\n",
    "                data = auto_df_no_gaps)\n",
    "fit = model.fit()\n",
    "\n",
    "results = fit.summary().tables[1]\n",
    "\n",
    "results_as_html = results.as_html()\n",
    "results_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "results_df[['coef', 'std err', 't', 'P>|t|']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42cb44-2396-47c3-b9ba-41b9da448a98",
   "metadata": {},
   "source": [
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737a3c0-6c80-47ec-b0a4-fb8a2ff9b9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52d811-c9db-4c66-8fc8-62efc533c38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ea2fc-443c-4fee-ab6e-7c43f25120ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "669e35b0-0ea3-4ae3-96f6-933d74b75588",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1d71f-5a11-4c0e-a78e-95b6f3f26fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(glm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f3f6b-0f2e-479f-93e2-e188b7cacb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glmnet_python\n",
    "from glmnet import glmnet; from glmnetPlot import glmnetPlot\n",
    "from glmnetPrint import glmnetPrint; from glmnetCoef import glmnetCoef; from glmnetPredict import glmnetPredict\n",
    "from cvglmnet import cvglmnet; from cvglmnetCoef import cvglmnetCoef\n",
    "from cvglmnetPlot import cvglmnetPlot; from cvglmnetPredict import cvglmnetPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812eb3f-7262-4610-af57-4e07ef7afd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2639ad-7f98-447a-895b-cfc5a2884173",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(auto_df_no_gaps['horsepower'].astype(np.float64).values)\n",
    "\n",
    "glm_fit = glmnet(x = X, y = auto_df_no_gaps['mpg'].astype(np.float64).values, family='gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f98eea-bfcc-456e-a245-29716bee731d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glmnetCoef(glm_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a494551-e3ed-40be-a54d-9190e697fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features.fit_transform(np.array(auto_df['horsepower'][0:4]).reshape(-1, 1))[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f075e92-1c2f-4789-9bc0-24251a1d6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "horsepower[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736d344-d7ff-4d04-843b-5aeac09694ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(x, p):\n",
    "    x = np.array(x)\n",
    "    X = np.transpose(np.vstack((x**k for k in range(p+1))))\n",
    "    return np.linalg.qr(X)[0][:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faacc0b-e036-410c-980b-1ddba0032686",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly(auto_df['horsepower'][0:4], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14fb09-94ea-4911-b6c8-c1c271d878d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df[['horsepower_poly_1', 'horsepower_poly_2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dae4f9-7309-439b-9c98-fab20533184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model2 = smf.ols(formula = 'mpg ~ poly(horsepower,2)', data = auto_df.iloc[train_idx-1])\n",
    "lm_fit2 = lm_model2.fit()\n",
    "pred = lm_fit2.predict(auto_df.iloc[test_idx]['horsepower'])\n",
    "((auto_df.iloc[test_idx]['mpg'] - pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e9562-21de-4b5c-9d18-3a6d8d245c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6704b0f-ea31-44f9-8312-935851f9e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model2 = smf.ols(formula = 'mpg ~ poly(horsepower, 2)', data = auto_df.iloc[train_idx-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f48819-7f0a-46dd-8a23-149fada350d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit2 = lm_model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c471ce5-9a93-4e8c-8464-dfd1a0abae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lm_fit2.predict(auto_df.iloc[test_idx]['horsepower'])\n",
    "((auto_df.iloc[test_idx]['mpg'] - pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f30af5-5f45-4f35-a037-72c6bb6d7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit2.predict(auto_df['horsepower'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e2d329-8e05-4dc9-a664-b2f5b477f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339bc79-4b7c-4a4d-b94a-d28b37552589",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df['horsepower'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafca683-eec1-437c-ba11-6db0d1d9cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model2 = smf.ols(formula = 'mpg ~ polynomial_features.fit_transform(np.array(auto_df.iloc[train_idx-1][\"horsepower\"]).reshape(-1,1))[:,1:]', data = auto_df.iloc[train_idx-1])\n",
    "\n",
    "lm_fit2 = lm_model2.fit()\n",
    "\n",
    "# poly.fit_transform(np.array(auto_df['horsepower'][0:4]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5c951-a226-4fb7-bd63-074cc58b6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e232317-4677-42b8-ab00-70ef71e7caeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "polynomial_features.fit_transform(np.array(auto_df.iloc[train_idx-1][\"horsepower\"]).reshape(-1,1))[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c4a08-191c-4d26-ab3a-928513af6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ortho_poly_fit(x, degree = 1):\n",
    "    n = degree + 1\n",
    "    x = np.asarray(x).flatten()\n",
    "    if(degree >= len(np.unique(x))):\n",
    "            stop(\"'degree' must be less than number of unique points\")\n",
    "    xbar = np.mean(x)\n",
    "    x = x - xbar\n",
    "    X = np.fliplr(np.vander(x, n))\n",
    "    q,r = np.linalg.qr(X)\n",
    "\n",
    "    z = np.diag(np.diag(r))\n",
    "    raw = np.dot(q, z)\n",
    "\n",
    "    norm2 = np.sum(raw**2, axis=0)\n",
    "    alpha = (np.sum((raw**2)*np.reshape(x,(-1,1)), axis=0)/norm2 + xbar)[:degree]\n",
    "    Z = raw / np.sqrt(norm2)\n",
    "    return Z[:,1:]##, norm2, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c11748-6854-4966-ba42-78ad145ae665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ortho_poly_fit(auto_df['horsepower'][0:20], 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757dbfa-e1bf-4a97-aa61-60ca964355e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_model2 = smf.ols(formula = 'mpg ~ ortho_poly_fit(horsepower, 2)', data = auto_df.iloc[train_idx-1])\n",
    "\n",
    "lm_fit2 = lm_model2.fit(method='qr')\n",
    "\n",
    "# poly.fit_transform(np.array(auto_df['horsepower'][0:4]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4067e-9c82-41ad-81f5-eed5f00e2b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4e5f6-262d-4ce5-9986-1254559edaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ortho_poly_fit(auto_df.iloc[train_idx - 1]['horsepower'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef80989-22bc-4ebb-aac0-58eeac9b5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ortho_poly_fit(auto_df.iloc[train_idx-1]['horsepower'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f93a0-4659-488a-a4e7-a3dd5ae4f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c78e89-054a-4b9f-86dc-1f901b7652b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(data={'h1':X[:,0], 'h2':X[:,1], 'mpg': auto_df['horsepower']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb22be2-68db-45ca-81ae-afe2161d8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lm_model2 = smf.ols(formula = 'mpg ~ h1 + h2', data = X_df.iloc[train_idx-1])\n",
    "\n",
    "lm_fit2 = lm_model2.fit()\n",
    "lm_fit2.summary()\n",
    "# poly.fit_transform(np.array(auto_df['horsepower'][0:4]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920e175-fe05-43b4-867d-f7a633e0f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.set_index(1, auto_df.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415fd84-b353-4a6e-9f58-2dacbebe0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = auto_df.set_index(np.arange(1,auto_df.shape[0]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c581cf-1dc4-4285-b9a3-2aa1b9e9acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dba1e5-2f5e-4306-ae3e-7d950c6ccb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model2 = smf.ols(formula = 'mpg ~ ortho_poly_fit(horsepower, 2)', data = test, subset=train_idx)\n",
    "\n",
    "lm_fit2 = lm_model2.fit(method='qr')\n",
    "\n",
    "lm_fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45c9ec-6f85-4526-8aa7-7e7fa15a518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit2.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3a47d-9311-4c2d-8cbe-e2a186d823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.iloc[train_idx-1]['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54514e9a-7d76-4dbb-9635-31325d9439e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_poly_fit(auto_df.iloc[train_idx-1]['horsepower'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e47b9-012a-47cf-a32b-ab1f773578ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
